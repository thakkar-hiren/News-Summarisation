{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "6_News_Summary",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thakkar-hiren/News-Summarisation/blob/main/6_News_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization Using BERT Embeddings and TextRank Algorithm\n",
        "This file contains an implementation of text summarization using BERT (Bidirectional Encoder Representations from Transformers) embeddings and the TextRank algorithm. The process begins by loading a dataset containing news articles and preprocessed text. The pre-trained BERT model and tokenizer are then loaded from the Hugging Face Transformers library. The text is tokenized into sentences, and BERT embeddings are obtained for each sentence using the pre-trained model. Cosine similarity is utilized to construct a similarity matrix based on the BERT embeddings. The TextRank algorithm is applied to rank sentences based on their similarity scores, and the top-ranked sentences are selected to form the summary. The number of sentences in the summary is customizable, with options for generating summaries of 3 or 5 sentences. Additionally, the file includes evaluation functions to compute the average ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores, providing insights into the quality of the generated summaries. This implementation leverages the power of BERT embeddings to capture contextual information and generate informative summaries, making it suitable for various text summarization tasks across different domains."
      ],
      "metadata": {
        "id": "_0sLekc6zYmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Libraries"
      ],
      "metadata": {
        "id": "65uMay_0znGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:28:58.647968Z",
          "iopub.execute_input": "2024-02-21T05:28:58.648685Z",
          "iopub.status.idle": "2024-02-21T05:29:11.091535Z",
          "shell.execute_reply.started": "2024-02-21T05:28:58.648647Z",
          "shell.execute_reply": "2024-02-21T05:29:11.090581Z"
        },
        "trusted": true,
        "id": "jBRcr1WQzT_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1QGknCbFF7C5IKQ69VlyhiCxVTn39sF30"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:29:15.842727Z",
          "iopub.execute_input": "2024-02-21T05:29:15.843738Z",
          "iopub.status.idle": "2024-02-21T05:29:24.03944Z",
          "shell.execute_reply.started": "2024-02-21T05:29:15.8437Z",
          "shell.execute_reply": "2024-02-21T05:29:24.038272Z"
        },
        "trusted": true,
        "id": "rjULHHrOzT__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:29:32.747013Z",
          "iopub.execute_input": "2024-02-21T05:29:32.747896Z",
          "iopub.status.idle": "2024-02-21T05:29:45.203101Z",
          "shell.execute_reply.started": "2024-02-21T05:29:32.747858Z",
          "shell.execute_reply": "2024-02-21T05:29:45.201813Z"
        },
        "trusted": true,
        "id": "Y5ctfS6wzUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "VcDiJKnezuRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "news_data = pd.read_csv('/kaggle/working/filtered_news_data.csv')\n",
        "news_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:30:52.057832Z",
          "iopub.execute_input": "2024-02-21T05:30:52.058812Z",
          "iopub.status.idle": "2024-02-21T05:30:52.633843Z",
          "shell.execute_reply.started": "2024-02-21T05:30:52.058771Z",
          "shell.execute_reply": "2024-02-21T05:30:52.632769Z"
        },
        "trusted": true,
        "id": "JwvL0RXbzUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:31:29.91704Z",
          "iopub.execute_input": "2024-02-21T05:31:29.918Z",
          "iopub.status.idle": "2024-02-21T05:31:29.92207Z",
          "shell.execute_reply.started": "2024-02-21T05:31:29.917964Z",
          "shell.execute_reply": "2024-02-21T05:31:29.921058Z"
        },
        "trusted": true,
        "id": "3FqWMkc-zUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:31:34.281664Z",
          "iopub.execute_input": "2024-02-21T05:31:34.28204Z",
          "iopub.status.idle": "2024-02-21T05:31:34.288795Z",
          "shell.execute_reply.started": "2024-02-21T05:31:34.282009Z",
          "shell.execute_reply": "2024-02-21T05:31:34.287721Z"
        },
        "trusted": true,
        "id": "piYpkCkezUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "uv9IdwjCzx8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:38:57.769913Z",
          "iopub.execute_input": "2024-02-21T05:38:57.770792Z",
          "iopub.status.idle": "2024-02-21T05:38:58.347837Z",
          "shell.execute_reply.started": "2024-02-21T05:38:57.770754Z",
          "shell.execute_reply": "2024-02-21T05:38:58.346804Z"
        },
        "trusted": true,
        "id": "BSxiEyDGzUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:35:25.779541Z",
          "iopub.execute_input": "2024-02-21T05:35:25.779931Z",
          "iopub.status.idle": "2024-02-21T05:35:25.787892Z",
          "shell.execute_reply.started": "2024-02-21T05:35:25.779898Z",
          "shell.execute_reply": "2024-02-21T05:35:25.786887Z"
        },
        "trusted": true,
        "id": "tD4jJELRzUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain BERT embeddings for a sentence\n",
        "def get_bert_embeddings(sentence):\n",
        "    tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        tokens = {key: value.to(device) for key, value in tokens.items()}\n",
        "        outputs = model(**tokens)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # Use mean pooling to obtain sentence embedding\n",
        "    return cls_embedding.to('cpu')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:39:23.188654Z",
          "iopub.execute_input": "2024-02-21T05:39:23.189408Z",
          "iopub.status.idle": "2024-02-21T05:39:23.195911Z",
          "shell.execute_reply.started": "2024-02-21T05:39:23.189379Z",
          "shell.execute_reply": "2024-02-21T05:39:23.194815Z"
        },
        "trusted": true,
        "id": "fSQ3xH85zUAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate similarity matrix based on BERT embeddings\n",
        "def cosine_similarity_matrix(embeddings):\n",
        "    embeddings_mean = torch.mean(embeddings, dim=1)\n",
        "    similarity_matrix = cosine_similarity(embeddings_mean, embeddings_mean)\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:35:32.609412Z",
          "iopub.execute_input": "2024-02-21T05:35:32.609774Z",
          "iopub.status.idle": "2024-02-21T05:35:32.615371Z",
          "shell.execute_reply.started": "2024-02-21T05:35:32.609745Z",
          "shell.execute_reply": "2024-02-21T05:35:32.614171Z"
        },
        "trusted": true,
        "id": "nN8hJ7kKzUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TextRank function\n",
        "def textrank(similarity_matrix):\n",
        "    damping_factor = 0.85\n",
        "    n_iterations = 250\n",
        "    n_sentences = similarity_matrix.shape[0]\n",
        "    ranks = np.ones(n_sentences) / n_sentences  # Initialize page ranks\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        new_ranks = (1 - damping_factor) / n_sentences + damping_factor * similarity_matrix.T.dot(ranks)\n",
        "        ranks = new_ranks\n",
        "    return ranks"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:35:35.35056Z",
          "iopub.execute_input": "2024-02-21T05:35:35.351309Z",
          "iopub.status.idle": "2024-02-21T05:35:35.357285Z",
          "shell.execute_reply.started": "2024-02-21T05:35:35.351276Z",
          "shell.execute_reply": "2024-02-21T05:35:35.356143Z"
        },
        "trusted": true,
        "id": "3o5Dt4yzzUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sentences(tokenized_sentences):\n",
        "    max_length = max(len(tokens) for tokens in tokenized_sentences)\n",
        "    padded_sentences = [tokens + ['[PAD]'] * (max_length - len(tokens)) for tokens in tokenized_sentences]\n",
        "    return padded_sentences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:35:39.456655Z",
          "iopub.execute_input": "2024-02-21T05:35:39.457567Z",
          "iopub.status.idle": "2024-02-21T05:35:39.462248Z",
          "shell.execute_reply.started": "2024-02-21T05:35:39.457534Z",
          "shell.execute_reply": "2024-02-21T05:35:39.461363Z"
        },
        "trusted": true,
        "id": "II2xsgrVzUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization function\n",
        "def summarize_article(article_text, nos=3):\n",
        "    tokenized_sentences = [tokenizer.tokenize(sentence) for sentence in sent_tokenize(article_text)]\n",
        "    padded_sentences = pad_sentences(tokenized_sentences)\n",
        "    sentence_embeddings = [get_bert_embeddings(tokens) for tokens in padded_sentences]\n",
        "    sentence_embeddings = torch.stack(sentence_embeddings, dim=0)\n",
        "\n",
        "    similarity_matrix = cosine_similarity_matrix(sentence_embeddings)\n",
        "    ranks = textrank(similarity_matrix)\n",
        "\n",
        "    n_summary_sentences = min(nos, len(tokenized_sentences))\n",
        "    top_sentence_indices = ranks.argsort()[-n_summary_sentences:][::-1]\n",
        "    predicted_summary = \" \".join([sent_tokenize(article_text)[i] for i in sorted(top_sentence_indices)])\n",
        "\n",
        "    return predicted_summary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:35:41.747729Z",
          "iopub.execute_input": "2024-02-21T05:35:41.748095Z",
          "iopub.status.idle": "2024-02-21T05:35:41.755265Z",
          "shell.execute_reply.started": "2024-02-21T05:35:41.748066Z",
          "shell.execute_reply": "2024-02-21T05:35:41.754267Z"
        },
        "trusted": true,
        "id": "EhqnzOzlzUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply summarization to each article\n",
        "news_data['predictedSummary_3'] = news_data['preprocessed_ctext'].apply(lambda x: summarize_article(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T05:39:31.411414Z",
          "iopub.execute_input": "2024-02-21T05:39:31.411831Z",
          "iopub.status.idle": "2024-02-21T05:59:05.492473Z",
          "shell.execute_reply.started": "2024-02-21T05:39:31.411799Z",
          "shell.execute_reply": "2024-02-21T05:59:05.491408Z"
        },
        "trusted": true,
        "id": "r5o_D_K7zUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply summarization to each article\n",
        "news_data['predictedSummary_5'] = news_data['preprocessed_ctext'].apply(lambda x: summarize_article(x,nos=5))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:13:20.880361Z",
          "iopub.execute_input": "2024-02-21T06:13:20.880815Z",
          "iopub.status.idle": "2024-02-21T06:33:03.767771Z",
          "shell.execute_reply.started": "2024-02-21T06:13:20.88078Z",
          "shell.execute_reply": "2024-02-21T06:33:03.766542Z"
        },
        "trusted": true,
        "id": "LlgSdtXOzUAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "-ks8n1oDzUAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:43:13.515398Z",
          "iopub.execute_input": "2024-02-21T06:43:13.515797Z",
          "iopub.status.idle": "2024-02-21T06:43:28.590865Z",
          "shell.execute_reply.started": "2024-02-21T06:43:13.515768Z",
          "shell.execute_reply": "2024-02-21T06:43:28.589806Z"
        },
        "trusted": true,
        "id": "zIRepjHnzUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation function\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def evaluate_summaries_3(news_data):\n",
        "    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n",
        "    rouge_scores = []\n",
        "\n",
        "    for idx, row in news_data.iterrows():\n",
        "        scores = scorer.score(target=row['preprocessed_text'], prediction=row['predictedSummary_3'])\n",
        "        rouge_scores.append(scores)\n",
        "\n",
        "    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n",
        "    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n",
        "    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n",
        "    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n",
        "    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n",
        "    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n",
        "    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n",
        "    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n",
        "    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n",
        "    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n",
        "    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n",
        "    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n",
        "    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n",
        "    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n",
        "    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:43:48.748843Z",
          "iopub.execute_input": "2024-02-21T06:43:48.749874Z",
          "iopub.status.idle": "2024-02-21T06:43:48.821016Z",
          "shell.execute_reply.started": "2024-02-21T06:43:48.749833Z",
          "shell.execute_reply": "2024-02-21T06:43:48.820102Z"
        },
        "trusted": true,
        "id": "dpG3toq6zUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summaries_5(news_data):\n",
        "    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n",
        "    rouge_scores = []\n",
        "\n",
        "    for idx, row in news_data.iterrows():\n",
        "        scores = scorer.score(target=row['preprocessed_text'], prediction=row['predictedSummary_5'])\n",
        "        rouge_scores.append(scores)\n",
        "\n",
        "    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n",
        "    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n",
        "    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n",
        "    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n",
        "    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n",
        "    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n",
        "    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
        "\n",
        "    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n",
        "    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n",
        "    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n",
        "    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n",
        "    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n",
        "    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n",
        "    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n",
        "    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n",
        "    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:44:04.619679Z",
          "iopub.execute_input": "2024-02-21T06:44:04.620616Z",
          "iopub.status.idle": "2024-02-21T06:44:04.631365Z",
          "shell.execute_reply.started": "2024-02-21T06:44:04.620578Z",
          "shell.execute_reply": "2024-02-21T06:44:04.630276Z"
        },
        "trusted": true,
        "id": "J8wKuQbuzUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For BERT:- \")\n",
        "print(\"Evaluation for the summary of 3 sentences: \\n\")\n",
        "evaluate_summaries_3(news_data)\n",
        "print(\"\\n\")\n",
        "print(\"Evaluation for the summary of 5 sentences: \\n\")\n",
        "evaluate_summaries_5(news_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:44:30.09842Z",
          "iopub.execute_input": "2024-02-21T06:44:30.09879Z",
          "iopub.status.idle": "2024-02-21T06:44:57.24187Z",
          "shell.execute_reply.started": "2024-02-21T06:44:30.098762Z",
          "shell.execute_reply": "2024-02-21T06:44:57.240874Z"
        },
        "trusted": true,
        "id": "XsvsoC2azUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_data['predictedSummary_3'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:45:46.368382Z",
          "iopub.execute_input": "2024-02-21T06:45:46.369145Z",
          "iopub.status.idle": "2024-02-21T06:45:46.376163Z",
          "shell.execute_reply.started": "2024-02-21T06:45:46.369102Z",
          "shell.execute_reply": "2024-02-21T06:45:46.375194Z"
        },
        "trusted": true,
        "id": "JelDFXlazUAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_data['predictedSummary_5'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-21T06:46:29.95085Z",
          "iopub.execute_input": "2024-02-21T06:46:29.95126Z",
          "iopub.status.idle": "2024-02-21T06:46:29.957505Z",
          "shell.execute_reply.started": "2024-02-21T06:46:29.951225Z",
          "shell.execute_reply": "2024-02-21T06:46:29.956442Z"
        },
        "trusted": true,
        "id": "cCL8N-OpzUAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNEMQZc-zUAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}