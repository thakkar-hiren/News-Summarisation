{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install transformers gdown rouge rouge_score -q","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:22:26.486932Z","iopub.execute_input":"2024-03-29T09:22:26.487328Z","iopub.status.idle":"2024-03-29T09:22:43.971479Z","shell.execute_reply.started":"2024-03-29T09:22:26.487299Z","shell.execute_reply":"2024-03-29T09:22:43.970319Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1QGknCbFF7C5IKQ69VlyhiCxVTn39sF30","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:23:01.441026Z","iopub.execute_input":"2024-03-29T09:23:01.441755Z","iopub.status.idle":"2024-03-29T09:23:09.832218Z","shell.execute_reply.started":"2024-03-29T09:23:01.441722Z","shell.execute_reply":"2024-03-29T09:23:09.831200Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1QGknCbFF7C5IKQ69VlyhiCxVTn39sF30\nTo: /kaggle/working/filtered_news_data.csv\n100%|██████████████████████████████████████| 16.6M/16.6M [00:00<00:00, 65.8MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Checking For GPU","metadata":{}},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:23:50.914117Z","iopub.execute_input":"2024-03-29T09:23:50.914552Z","iopub.status.idle":"2024-03-29T09:23:55.431893Z","shell.execute_reply.started":"2024-03-29T09:23:50.914519Z","shell.execute_reply":"2024-03-29T09:23:55.430827Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nnews_data = pd.read_csv('/kaggle/working/filtered_news_data.csv')\nnews_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:24:26.242622Z","iopub.execute_input":"2024-03-29T09:24:26.243359Z","iopub.status.idle":"2024-03-29T09:24:27.682415Z","shell.execute_reply.started":"2024-03-29T09:24:26.243328Z","shell.execute_reply":"2024-03-29T09:24:27.681372Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text  \\\n0           0  The Administration of Union Territory Daman an...   \n1           2  The Indira Gandhi Institute of Medical Science...   \n2           4  Hotels in Maharashtra will train their staff t...   \n3           5  A 32-year-old man on Wednesday was found hangi...   \n4           6  The Delhi High Court reduced the compensation ...   \n\n                                               ctext  text_len  ctext_len  \\\n0  The Daman and Diu administration on Wednesday ...       358       2313   \n1  The Indira Gandhi Institute of Medical Science...       398       2112   \n2  Hotels in Mumbai and other Indian cities are t...       366       3249   \n3  An alleged suspect in a kidnapping case was fo...       347       2247   \n4  In an interesting ruling, the Delhi high court...       361       2367   \n\n   text_sent_count  text_word_count  ctext_sent_count  ctext_word_count  \\\n0                2               62                16               413   \n1                3               70                18               379   \n2                3               67                 8               569   \n3                3               63                23               440   \n4                3               70                11               444   \n\n                                   preprocessed_text  \\\n0  the administration of union territory daman an...   \n1  the indira gandhi institute of medical science...   \n2  hotels in maharashtra will train their staff t...   \n3  a 32yearold man on wednesday was found hanging...   \n4  the delhi high court reduced the compensation ...   \n\n                                  preprocessed_ctext  \n0  the daman and diu administration on wednesday ...  \n1  the indira gandhi institute of medical science...  \n2  hotels in mumbai and other indian cities are t...  \n3  an alleged suspect in a kidnapping case was fo...  \n4  in an interesting ruling the delhi high court ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>ctext</th>\n      <th>text_len</th>\n      <th>ctext_len</th>\n      <th>text_sent_count</th>\n      <th>text_word_count</th>\n      <th>ctext_sent_count</th>\n      <th>ctext_word_count</th>\n      <th>preprocessed_text</th>\n      <th>preprocessed_ctext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>The Administration of Union Territory Daman an...</td>\n      <td>The Daman and Diu administration on Wednesday ...</td>\n      <td>358</td>\n      <td>2313</td>\n      <td>2</td>\n      <td>62</td>\n      <td>16</td>\n      <td>413</td>\n      <td>the administration of union territory daman an...</td>\n      <td>the daman and diu administration on wednesday ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>The Indira Gandhi Institute of Medical Science...</td>\n      <td>The Indira Gandhi Institute of Medical Science...</td>\n      <td>398</td>\n      <td>2112</td>\n      <td>3</td>\n      <td>70</td>\n      <td>18</td>\n      <td>379</td>\n      <td>the indira gandhi institute of medical science...</td>\n      <td>the indira gandhi institute of medical science...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Hotels in Maharashtra will train their staff t...</td>\n      <td>Hotels in Mumbai and other Indian cities are t...</td>\n      <td>366</td>\n      <td>3249</td>\n      <td>3</td>\n      <td>67</td>\n      <td>8</td>\n      <td>569</td>\n      <td>hotels in maharashtra will train their staff t...</td>\n      <td>hotels in mumbai and other indian cities are t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>A 32-year-old man on Wednesday was found hangi...</td>\n      <td>An alleged suspect in a kidnapping case was fo...</td>\n      <td>347</td>\n      <td>2247</td>\n      <td>3</td>\n      <td>63</td>\n      <td>23</td>\n      <td>440</td>\n      <td>a 32yearold man on wednesday was found hanging...</td>\n      <td>an alleged suspect in a kidnapping case was fo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>The Delhi High Court reduced the compensation ...</td>\n      <td>In an interesting ruling, the Delhi high court...</td>\n      <td>361</td>\n      <td>2367</td>\n      <td>3</td>\n      <td>70</td>\n      <td>11</td>\n      <td>444</td>\n      <td>the delhi high court reduced the compensation ...</td>\n      <td>in an interesting ruling the delhi high court ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preparing Data","metadata":{}},{"cell_type":"code","source":"news_data = news_data[['preprocessed_text', 'preprocessed_ctext']]\nnews_data.columns = ['summary', 'news']\nnews_data['news'] = 'summarize: ' + news_data['news']\nnews_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:25:05.093623Z","iopub.execute_input":"2024-03-29T09:25:05.094668Z","iopub.status.idle":"2024-03-29T09:25:05.121424Z","shell.execute_reply.started":"2024-03-29T09:25:05.094622Z","shell.execute_reply":"2024-03-29T09:25:05.120358Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             summary  \\\n0  the administration of union territory daman an...   \n1  the indira gandhi institute of medical science...   \n2  hotels in maharashtra will train their staff t...   \n3  a 32yearold man on wednesday was found hanging...   \n4  the delhi high court reduced the compensation ...   \n\n                                                news  \n0  summarize: the daman and diu administration on...  \n1  summarize: the indira gandhi institute of medi...  \n2  summarize: hotels in mumbai and other indian c...  \n3  summarize: an alleged suspect in a kidnapping ...  \n4  summarize: in an interesting ruling the delhi ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>news</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the administration of union territory daman an...</td>\n      <td>summarize: the daman and diu administration on...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the indira gandhi institute of medical science...</td>\n      <td>summarize: the indira gandhi institute of medi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hotels in maharashtra will train their staff t...</td>\n      <td>summarize: hotels in mumbai and other indian c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a 32yearold man on wednesday was found hanging...</td>\n      <td>summarize: an alleged suspect in a kidnapping ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the delhi high court reduced the compensation ...</td>\n      <td>summarize: in an interesting ruling the delhi ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Converting Pandas Dataframe to Hugging Face Dataset","metadata":{}},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_news, test_news = train_test_split(news_data, test_size=0.1, shuffle = True)\nprint(\"No. of Train and Validation Datapoints: \",len(train_news))\nprint(\"No. of Test Datapoints: \",len(test_news))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:25:46.980461Z","iopub.execute_input":"2024-03-29T09:25:46.981366Z","iopub.status.idle":"2024-03-29T09:25:48.336025Z","shell.execute_reply.started":"2024-03-29T09:25:46.981333Z","shell.execute_reply":"2024-03-29T09:25:48.335009Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"No. of Train and Validation Datapoints:  3524\nNo. of Test Datapoints:  392\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the global pandas version of train and test dataframes\nglobal_train_news = train_news\nglobal_test_news = test_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:26:59.439093Z","iopub.execute_input":"2024-03-29T09:26:59.440229Z","iopub.status.idle":"2024-03-29T09:26:59.444342Z","shell.execute_reply.started":"2024-03-29T09:26:59.440199Z","shell.execute_reply":"2024-03-29T09:26:59.443359Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Saving global train and test data as csv for backup\nglobal_train_news.to_csv('/kaggle/working/train_news.csv', index=False)\nglobal_test_news.to_csv('/kaggle/working/test_news.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:22:19.161842Z","iopub.execute_input":"2024-03-29T10:22:19.162827Z","iopub.status.idle":"2024-03-29T10:22:19.544668Z","shell.execute_reply.started":"2024-03-29T10:22:19.162794Z","shell.execute_reply":"2024-03-29T10:22:19.543778Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Converting train set to hugging face dataset\nimport datasets\nfrom datasets import Dataset, DatasetDict\n\ntrain_news = datasets.Dataset.from_pandas(train_news)\ntrain_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:28:03.596983Z","iopub.execute_input":"2024-03-29T09:28:03.597384Z","iopub.status.idle":"2024-03-29T09:28:05.017810Z","shell.execute_reply.started":"2024-03-29T09:28:03.597358Z","shell.execute_reply":"2024-03-29T09:28:05.016905Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['summary', 'news', '__index_level_0__'],\n    num_rows: 3524\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning hugging face dataset\ntrain_news = train_news.remove_columns([\"__index_level_0__\"])\ntrain_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:28:39.632123Z","iopub.execute_input":"2024-03-29T09:28:39.633351Z","iopub.status.idle":"2024-03-29T09:28:39.641813Z","shell.execute_reply.started":"2024-03-29T09:28:39.633306Z","shell.execute_reply":"2024-03-29T09:28:39.640842Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['summary', 'news'],\n    num_rows: 3524\n})"},"metadata":{}}]},{"cell_type":"code","source":"# split train into train and val\ntrain_news = train_news.train_test_split(test_size=0.2, shuffle=True)\ntrain_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:29:00.787219Z","iopub.execute_input":"2024-03-29T09:29:00.787590Z","iopub.status.idle":"2024-03-29T09:29:00.814317Z","shell.execute_reply.started":"2024-03-29T09:29:00.787560Z","shell.execute_reply":"2024-03-29T09:29:00.813515Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['summary', 'news'],\n        num_rows: 2819\n    })\n    test: Dataset({\n        features: ['summary', 'news'],\n        num_rows: 705\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Fitting into dataset dict\ntrain_val_dataset = DatasetDict({\n    'train': train_news[\"train\"],\n    'val': train_news['test']})","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:29:15.553258Z","iopub.execute_input":"2024-03-29T09:29:15.553657Z","iopub.status.idle":"2024-03-29T09:29:15.558356Z","shell.execute_reply.started":"2024-03-29T09:29:15.553628Z","shell.execute_reply":"2024-03-29T09:29:15.557335Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# T5 Small Modeling","metadata":{}},{"cell_type":"markdown","source":"## Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nt5_small_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\nt5_small_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:30:15.670206Z","iopub.execute_input":"2024-03-29T09:30:15.670748Z","iopub.status.idle":"2024-03-29T09:30:22.794044Z","shell.execute_reply.started":"2024-03-29T09:30:15.670717Z","shell.execute_reply":"2024-03-29T09:30:22.793303Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52840a3133914df4a3505aae63bebb33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76061e2aa121425698ea3321e736f047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67626223110446679aeb75658b9a15e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb1e4f340ea4228b34efd898e28ec7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d756067b9c76472ca2f137e46d7feb3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"785dcbbc216e4be582837194275e9b9e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def prepare_dataset(data):\n    inputs = data[\"news\"]\n    model_inputs = t5_small_tokenizer(inputs, max_length=512, truncation=True)\n    labels = t5_small_tokenizer(text_target=data[\"summary\"], max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:31:37.591986Z","iopub.execute_input":"2024-03-29T09:31:37.592984Z","iopub.status.idle":"2024-03-29T09:31:37.598255Z","shell.execute_reply.started":"2024-03-29T09:31:37.592954Z","shell.execute_reply":"2024-03-29T09:31:37.597334Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"t5_small_tokenized_data = train_val_dataset.map(prepare_dataset, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:32:32.253767Z","iopub.execute_input":"2024-03-29T09:32:32.254658Z","iopub.status.idle":"2024-03-29T09:32:43.861598Z","shell.execute_reply.started":"2024-03-29T09:32:32.254624Z","shell.execute_reply":"2024-03-29T09:32:43.860524Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e35b4ad21684580b5afd6e6711cdc91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fa315f253154c33879dec9be854728a"}},"metadata":{}}]},{"cell_type":"code","source":"t5_small_tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:33:00.091658Z","iopub.execute_input":"2024-03-29T09:33:00.092511Z","iopub.status.idle":"2024-03-29T09:33:00.098329Z","shell.execute_reply.started":"2024-03-29T09:33:00.092479Z","shell.execute_reply":"2024-03-29T09:33:00.097319Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2819\n    })\n    val: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 705\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer= t5_small_tokenizer, model=t5_small_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:34:26.291692Z","iopub.execute_input":"2024-03-29T09:34:26.292063Z","iopub.status.idle":"2024-03-29T09:34:37.400599Z","shell.execute_reply.started":"2024-03-29T09:34:26.292039Z","shell.execute_reply":"2024-03-29T09:34:37.399772Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2024-03-29 09:34:28.395890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 09:34:28.396043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 09:34:28.572345: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Compute Metrics","metadata":{}},{"cell_type":"code","source":"from rouge import Rouge\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = t5_small_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, t5_small_tokenizer.pad_token_id)\n    decoded_labels = t5_small_tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = Rouge().get_scores(decoded_preds, decoded_labels, avg=True, ignore_empty=True)\n\n    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    # result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:35:43.800721Z","iopub.execute_input":"2024-03-29T09:35:43.801550Z","iopub.status.idle":"2024-03-29T09:35:43.810379Z","shell.execute_reply.started":"2024-03-29T09:35:43.801437Z","shell.execute_reply":"2024-03-29T09:35:43.809558Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Setting Training Arguments","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"t5-small-news-sum-fine\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:37:16.790350Z","iopub.execute_input":"2024-03-29T09:37:16.791269Z","iopub.status.idle":"2024-03-29T09:37:16.824371Z","shell.execute_reply.started":"2024-03-29T09:37:16.791237Z","shell.execute_reply":"2024-03-29T09:37:16.823648Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model = t5_small_model,\n    args = training_args,\n    train_dataset = t5_small_tokenized_data[\"train\"],\n    eval_dataset = t5_small_tokenized_data[\"val\"],\n    tokenizer = t5_small_tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:38:44.858730Z","iopub.execute_input":"2024-03-29T09:38:44.859464Z","iopub.status.idle":"2024-03-29T09:38:44.917410Z","shell.execute_reply.started":"2024-03-29T09:38:44.859433Z","shell.execute_reply":"2024-03-29T09:38:44.916415Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:38:57.868862Z","iopub.execute_input":"2024-03-29T09:38:57.869598Z","iopub.status.idle":"2024-03-29T09:49:21.549339Z","shell.execute_reply.started":"2024-03-29T09:38:57.869568Z","shell.execute_reply":"2024-03-29T09:49:21.548497Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [885/885 10:19, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.799671</td>\n      <td>{'r': 0.15908538565382108, 'p': 0.6461251282659629, 'f': 0.2527181961734281}</td>\n      <td>{'r': 0.06735686067093552, 'p': 0.3541911665722681, 'f': 0.11203090086144164}</td>\n      <td>{'r': 0.14640446701355142, 'p': 0.5958883047594268, 'f': 0.23267297486728808}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.755471</td>\n      <td>{'r': 0.16144930472795405, 'p': 0.6513760132915664, 'f': 0.2561248130643206}</td>\n      <td>{'r': 0.06945204879884524, 'p': 0.3615431482484053, 'f': 0.11532792625730404}</td>\n      <td>{'r': 0.14864695049714508, 'p': 0.6009034987389511, 'f': 0.23589322556949116}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.952600</td>\n      <td>1.739642</td>\n      <td>{'r': 0.16259322276324512, 'p': 0.6545823934559862, 'f': 0.25785767200736864}</td>\n      <td>{'r': 0.07020101198635677, 'p': 0.36497510045695325, 'f': 0.11657172018558735}</td>\n      <td>{'r': 0.14941851327848202, 'p': 0.6029044696785627, 'f': 0.2370518674419431}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.952600</td>\n      <td>1.729928</td>\n      <td>{'r': 0.16303760528221423, 'p': 0.6549508381110389, 'f': 0.25841781212514314}</td>\n      <td>{'r': 0.07054610267107185, 'p': 0.36668576185785234, 'f': 0.11712465550530764}</td>\n      <td>{'r': 0.14986077105974668, 'p': 0.6042206573151508, 'f': 0.23769349478649066}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.952600</td>\n      <td>1.726962</td>\n      <td>{'r': 0.1629178931044338, 'p': 0.6559093988568335, 'f': 0.2583224821375902}</td>\n      <td>{'r': 0.07065762114180346, 'p': 0.3682244418539791, 'f': 0.11735158230760047}</td>\n      <td>{'r': 0.14986402840367127, 'p': 0.6056132796652199, 'f': 0.23778793843267182}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=885, training_loss=1.922504179356462, metrics={'train_runtime': 623.3571, 'train_samples_per_second': 22.611, 'train_steps_per_second': 1.42, 'total_flos': 1907642691747840.0, 'train_loss': 1.922504179356462, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Saving Model","metadata":{}},{"cell_type":"code","source":"# save the model\nmodel_path = \"t5-small-news-sum-fine\"\ntrainer.save_model(model_path)\nt5_small_tokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:50:36.846536Z","iopub.execute_input":"2024-03-29T09:50:36.847407Z","iopub.status.idle":"2024-03-29T09:50:37.389356Z","shell.execute_reply.started":"2024-03-29T09:50:36.847361Z","shell.execute_reply":"2024-03-29T09:50:37.388482Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('t5-small-news-sum-fine/tokenizer_config.json',\n 't5-small-news-sum-fine/special_tokens_map.json',\n 't5-small-news-sum-fine/spiece.model',\n 't5-small-news-sum-fine/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Inferencing","metadata":{}},{"cell_type":"markdown","source":"### Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/t5-small-news-sum-fine\").to(device)\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/working/t5-small-news-sum-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:51:51.687960Z","iopub.execute_input":"2024-03-29T09:51:51.688320Z","iopub.status.idle":"2024-03-29T09:51:52.341712Z","shell.execute_reply.started":"2024-03-29T09:51:51.688294Z","shell.execute_reply":"2024-03-29T09:51:52.340693Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Create Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nt5_small_summarizer = pipeline(\"summarization\", model = model,tokenizer = tokenizer, device=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:55:29.584097Z","iopub.execute_input":"2024-03-29T09:55:29.584718Z","iopub.status.idle":"2024-03-29T09:55:29.663455Z","shell.execute_reply.started":"2024-03-29T09:55:29.584686Z","shell.execute_reply":"2024-03-29T09:55:29.662521Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Inference on some instances","metadata":{}},{"cell_type":"code","source":"for i in range(3):\n    summary = t5_small_summarizer(test_news['news'].iloc[i])\n    print(\"Reference Summary:- \", test_news['summary'].iloc[i])\n    print(\"\\nGenerated Summary:- \",summary[0]['summary_text'])\n    print(\"==\"*50)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:55:33.580198Z","iopub.execute_input":"2024-03-29T09:55:33.580579Z","iopub.status.idle":"2024-03-29T09:55:37.077359Z","shell.execute_reply.started":"2024-03-29T09:55:33.580550Z","shell.execute_reply":"2024-03-29T09:55:37.076408Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Reference Summary:-  the indian space research organisation isro is set to launch record 103 satellites in a single flight in february first week . as many as 100 of the satellites to be launched are from foreign nations . earlier isro had said it will launch 83 satellites but the launch got delayed due to the addition of more satellites an official said .\n\nGenerated Summary:-  the indian space research organisation isro is set to launch 103 satellites in one go using its workhorse pslvc37 in the first week of february . as many as 100 of the satellites set for launch belong to foreign nations including the united states and germany .\n====================================================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 197. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\n","output_type":"stream"},{"name":"stdout","text":"Reference Summary:-  women and children will be allowed to use toilet facilities at hotels and restaurants including fivestars in south delhi for free from may 1 . security concerns coupled with the fact that some restaurants and bars dont allow single males made us keep men out of the scheme for now national restaurants association head riaz amlani said .\n\nGenerated Summary:-  south delhi municipal corporation sdmc commissioner puneet kumar goel said that hotels restaurants and eateries in the area will open their toilets to public use from may 1 . however men have been kept of out of the scheme due to privacy issues cited by various hotel associations .\n====================================================================================================\n\nReference Summary:-  an image of a pregnant us president donald trump being hugged by russian president vladimir putin from behind was projected on buildings in new york along with lovethroughhate . the image was a part of an ad campaign by the dating app hater . were just trying to make people laugh . through humour hate can turn into love the apps representatives said .\n\nGenerated Summary:-  the image of russian president vladimir putin embracing the us president donald trump from behind was projected on some buildings in new york and neighbourhoods williamsburg and chelsea with hashtag lovethroughhate . more than being a part of an antitrump resistance which has lingered since he started campaigning for us president post this was a publicity stunt by a dating app called hater .\n====================================================================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing on Test Set","metadata":{}},{"cell_type":"code","source":"def generate_summary_t5(text):\n    summary = t5_small_summarizer(text)\n    return summary[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:57:48.303265Z","iopub.execute_input":"2024-03-29T09:57:48.303701Z","iopub.status.idle":"2024-03-29T09:57:48.308554Z","shell.execute_reply.started":"2024-03-29T09:57:48.303672Z","shell.execute_reply":"2024-03-29T09:57:48.307675Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"test_news['t5_small_summary'] = test_news['news'].apply(lambda x: generate_summary_t5(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:57:59.012933Z","iopub.execute_input":"2024-03-29T09:57:59.013302Z","iopub.status.idle":"2024-03-29T10:05:26.094206Z","shell.execute_reply.started":"2024-03-29T09:57:59.013275Z","shell.execute_reply":"2024-03-29T10:05:26.093326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 197. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\nYour max_length is set to 200, but your input_length is only 115. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\nToken indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nYour max_length is set to 200, but your input_length is only 170. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\nYour max_length is set to 200, but your input_length is only 142. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\nYour max_length is set to 200, but your input_length is only 140. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\nYour max_length is set to 200, but your input_length is only 68. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\nYour max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\nYour max_length is set to 200, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\nYour max_length is set to 200, but your input_length is only 177. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=88)\nYour max_length is set to 200, but your input_length is only 106. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=53)\nYour max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\nYour max_length is set to 200, but your input_length is only 175. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 199. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\nYour max_length is set to 200, but your input_length is only 198. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\nYour max_length is set to 200, but your input_length is only 196. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\nYour max_length is set to 200, but your input_length is only 164. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=82)\nYour max_length is set to 200, but your input_length is only 144. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\nYour max_length is set to 200, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\nYour max_length is set to 200, but your input_length is only 56. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\nYour max_length is set to 200, but your input_length is only 130. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\nYour max_length is set to 200, but your input_length is only 175. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 174. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\nYour max_length is set to 200, but your input_length is only 151. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\nYour max_length is set to 200, but your input_length is only 154. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\nYour max_length is set to 200, but your input_length is only 160. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=80)\nYour max_length is set to 200, but your input_length is only 189. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=94)\nYour max_length is set to 200, but your input_length is only 63. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\nYour max_length is set to 200, but your input_length is only 172. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\nYour max_length is set to 200, but your input_length is only 155. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\nYour max_length is set to 200, but your input_length is only 157. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=78)\nYour max_length is set to 200, but your input_length is only 190. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\nYour max_length is set to 200, but your input_length is only 119. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\nYour max_length is set to 200, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\nYour max_length is set to 200, but your input_length is only 176. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=88)\nYour max_length is set to 200, but your input_length is only 89. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\nYour max_length is set to 200, but your input_length is only 138. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\nYour max_length is set to 200, but your input_length is only 55. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\nYour max_length is set to 200, but your input_length is only 180. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\nYour max_length is set to 200, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\nYour max_length is set to 200, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:06:38.350319Z","iopub.execute_input":"2024-03-29T10:06:38.351082Z","iopub.status.idle":"2024-03-29T10:06:38.364605Z","shell.execute_reply.started":"2024-03-29T10:06:38.351046Z","shell.execute_reply":"2024-03-29T10:06:38.363611Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                                summary  \\\n1492  the indian space research organisation isro is...   \n3070  women and children will be allowed to use toil...   \n895   an image of a pregnant us president donald tru...   \n3867  banking operations across the country came to ...   \n3707  indian national congress could manage to win o...   \n...                                                 ...   \n1350  sasi gangadharan a semiparalysed man from kera...   \n1384  usbased researchers have identified that the h...   \n2960  aap mla kapil mishra who was sacked on saturda...   \n1119  a child rights commission in tamil nadu has re...   \n2348  the indian railways has decided to allow forei...   \n\n                                                   news  \\\n1492  summarize: the indian space research organisat...   \n3070  summarize: starting monday women and children ...   \n895   summarize: the image of russian president vlad...   \n3867  summarize: banking operations across the count...   \n3707  summarize: six out of 10 assembly seats in ame...   \n...                                                 ...   \n1350  summarize: eighteen years ago sasi gangadharan...   \n1384  summarize: washington jan 10 pti the human app...   \n2960  summarize: rumblings in the aam aadmi party co...   \n1119  summarize: after a complaint filed by a child ...   \n2348  summarize: new delhi jul 3 pti now foreign tou...   \n\n                                       t5_small_summary  \n1492  the indian space research organisation isro is...  \n3070  south delhi municipal corporation sdmc commiss...  \n895   the image of russian president vladimir putin ...  \n3867  banking operations across the country came to ...  \n3707  six out of 10 assembly seats in amethi and rae...  \n...                                                 ...  \n1350  sasi gangadharan a coconut tree climber from t...  \n1384  the human appendix a narrow pouch that project...  \n2960  delhi water minister kapil mishra has been sac...  \n1119  tamil nadu commission for protection of child ...  \n2348  new delhi jul 3 pti now foreign tourists can b...  \n\n[392 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>news</th>\n      <th>t5_small_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1492</th>\n      <td>the indian space research organisation isro is...</td>\n      <td>summarize: the indian space research organisat...</td>\n      <td>the indian space research organisation isro is...</td>\n    </tr>\n    <tr>\n      <th>3070</th>\n      <td>women and children will be allowed to use toil...</td>\n      <td>summarize: starting monday women and children ...</td>\n      <td>south delhi municipal corporation sdmc commiss...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>an image of a pregnant us president donald tru...</td>\n      <td>summarize: the image of russian president vlad...</td>\n      <td>the image of russian president vladimir putin ...</td>\n    </tr>\n    <tr>\n      <th>3867</th>\n      <td>banking operations across the country came to ...</td>\n      <td>summarize: banking operations across the count...</td>\n      <td>banking operations across the country came to ...</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>indian national congress could manage to win o...</td>\n      <td>summarize: six out of 10 assembly seats in ame...</td>\n      <td>six out of 10 assembly seats in amethi and rae...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>sasi gangadharan a semiparalysed man from kera...</td>\n      <td>summarize: eighteen years ago sasi gangadharan...</td>\n      <td>sasi gangadharan a coconut tree climber from t...</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>usbased researchers have identified that the h...</td>\n      <td>summarize: washington jan 10 pti the human app...</td>\n      <td>the human appendix a narrow pouch that project...</td>\n    </tr>\n    <tr>\n      <th>2960</th>\n      <td>aap mla kapil mishra who was sacked on saturda...</td>\n      <td>summarize: rumblings in the aam aadmi party co...</td>\n      <td>delhi water minister kapil mishra has been sac...</td>\n    </tr>\n    <tr>\n      <th>1119</th>\n      <td>a child rights commission in tamil nadu has re...</td>\n      <td>summarize: after a complaint filed by a child ...</td>\n      <td>tamil nadu commission for protection of child ...</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>the indian railways has decided to allow forei...</td>\n      <td>summarize: new delhi jul 3 pti now foreign tou...</td>\n      <td>new delhi jul 3 pti now foreign tourists can b...</td>\n    </tr>\n  </tbody>\n</table>\n<p>392 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate on Test Data","metadata":{}},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef evaluate_test_summaries(news_data):\n    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n    rouge_scores = []\n\n    for idx, row in test_news.iterrows():\n        scores = scorer.score(target=row['summary'], prediction=row['t5_small_summary'])\n        rouge_scores.append(scores)\n\n    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n\n    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n\n    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n\n    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:07:41.953959Z","iopub.execute_input":"2024-03-29T10:07:41.954659Z","iopub.status.idle":"2024-03-29T10:07:43.000272Z","shell.execute_reply.started":"2024-03-29T10:07:41.954628Z","shell.execute_reply":"2024-03-29T10:07:42.999127Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(\"For T5-Small (FineTuned):- \")\nprint(\"\\nEvaluation for the test summary: \\n\")\nevaluate_test_summaries(test_news)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:08:18.448688Z","iopub.execute_input":"2024-03-29T10:08:18.449391Z","iopub.status.idle":"2024-03-29T10:08:19.477229Z","shell.execute_reply.started":"2024-03-29T10:08:18.449357Z","shell.execute_reply":"2024-03-29T10:08:19.476244Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"For T5-Small (FineTuned):- \n\nEvaluation for the test summary: \n\nAverage ROUGE-1 Precision:  0.47245357485299827\nAverage ROUGE-1 Recall:  0.43645387053163986\nAverage ROUGE-1 F1-Score:  0.4480127211825521\nAverage ROUGE-2 Precision:  0.2405866159498558\nAverage ROUGE-2 Recall:  0.22256570251633492\nAverage ROUGE-2 F1-Score:  0.22822762309677963\nAverage ROUGE-L Precision:  0.351249264194184\nAverage ROUGE-L Recall:  0.3238438765256885\nAverage ROUGE-L F1-Score:  0.33267878929317674\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download the Saved Model","metadata":{}},{"cell_type":"markdown","source":"### Create Zip File","metadata":{}},{"cell_type":"code","source":"import shutil\n# Define the directory containing your model files\nmodel_directory = \"/kaggle/working/t5-small-news-sum-fine\"\n# Define the name for your zip file\nzip_file_name = \"t5-small-news-sum-fine\"\n# Create a zip file containing the model directory\nshutil.make_archive(zip_file_name, 'zip', model_directory)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:15:40.546315Z","iopub.execute_input":"2024-03-29T10:15:40.547170Z","iopub.status.idle":"2024-03-29T10:16:42.430610Z","shell.execute_reply.started":"2024-03-29T10:15:40.547139Z","shell.execute_reply":"2024-03-29T10:16:42.429518Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/t5-small-news-sum-fine.zip'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Generate Downloadable Link","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:17:25.778661Z","iopub.execute_input":"2024-03-29T10:17:25.779070Z","iopub.status.idle":"2024-03-29T10:17:26.882663Z","shell.execute_reply.started":"2024-03-29T10:17:25.779041Z","shell.execute_reply":"2024-03-29T10:17:26.881265Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"filtered_news_data.csv\tt5-small-news-sum-fine\tt5-small-news-sum-fine.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r't5-small-news-sum-fine.zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:17:43.960957Z","iopub.execute_input":"2024-03-29T10:17:43.961402Z","iopub.status.idle":"2024-03-29T10:17:43.970149Z","shell.execute_reply.started":"2024-03-29T10:17:43.961369Z","shell.execute_reply":"2024-03-29T10:17:43.969057Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/t5-small-news-sum-fine.zip","text/html":"<a href='t5-small-news-sum-fine.zip' target='_blank'>t5-small-news-sum-fine.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Empty Cache Memory","metadata":{}},{"cell_type":"code","source":"# Free up memory\nimport torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:25:58.548543Z","iopub.execute_input":"2024-03-29T10:25:58.549706Z","iopub.status.idle":"2024-03-29T10:25:58.864838Z","shell.execute_reply.started":"2024-03-29T10:25:58.549669Z","shell.execute_reply":"2024-03-29T10:25:58.863709Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# T5 Base Modeling","metadata":{}},{"cell_type":"markdown","source":"## Loading Tokenizer and Model","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nt5_base_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\nt5_base_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:28:18.048386Z","iopub.execute_input":"2024-03-29T10:28:18.049369Z","iopub.status.idle":"2024-03-29T10:28:24.300812Z","shell.execute_reply.started":"2024-03-29T10:28:18.049335Z","shell.execute_reply":"2024-03-29T10:28:24.299790Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c7eae9882a145f3911ec552f4d1db97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87135f57a3804fe8bccaa01b2ef25b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3bd8d00d5c4438489646be28b6e760b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66050bf5466241e9a1378b7f36b53259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa749ae2cc0f4299a7f648bcc3fd0167"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def prepare_dataset(data):\n    inputs = data[\"news\"]\n    model_inputs = t5_base_tokenizer(inputs, max_length=512, truncation=True)\n    labels = t5_base_tokenizer(text_target=data[\"summary\"], max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:29:20.646662Z","iopub.execute_input":"2024-03-29T10:29:20.647341Z","iopub.status.idle":"2024-03-29T10:29:20.653227Z","shell.execute_reply.started":"2024-03-29T10:29:20.647308Z","shell.execute_reply":"2024-03-29T10:29:20.652190Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"t5_base_tokenized_data = train_val_dataset.map(prepare_dataset, batched=True)\nt5_base_tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:32:52.445416Z","iopub.execute_input":"2024-03-29T10:32:52.446335Z","iopub.status.idle":"2024-03-29T10:33:04.327163Z","shell.execute_reply.started":"2024-03-29T10:32:52.446304Z","shell.execute_reply":"2024-03-29T10:33:04.326243Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a736facf87f346d5a5a4fc00a7fb83ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b07b05678cfc45a4887f06830b0623e4"}},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2819\n    })\n    val: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 705\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer= t5_base_tokenizer, model=t5_base_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:30:04.382213Z","iopub.execute_input":"2024-03-29T10:30:04.383078Z","iopub.status.idle":"2024-03-29T10:30:04.387805Z","shell.execute_reply.started":"2024-03-29T10:30:04.383045Z","shell.execute_reply":"2024-03-29T10:30:04.386538Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Compute Metrics","metadata":{}},{"cell_type":"code","source":"from rouge import Rouge\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = t5_base_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, t5_base_tokenizer.pad_token_id)\n    decoded_labels = t5_base_tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = Rouge().get_scores(decoded_preds, decoded_labels, avg=True, ignore_empty=True)\n\n    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    # result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:30:48.038766Z","iopub.execute_input":"2024-03-29T10:30:48.039193Z","iopub.status.idle":"2024-03-29T10:30:48.046574Z","shell.execute_reply.started":"2024-03-29T10:30:48.039162Z","shell.execute_reply":"2024-03-29T10:30:48.045436Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Setting Training Arguments","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"t5-base-news-sum-fine\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:31:44.248891Z","iopub.execute_input":"2024-03-29T10:31:44.249305Z","iopub.status.idle":"2024-03-29T10:31:44.256582Z","shell.execute_reply.started":"2024-03-29T10:31:44.249275Z","shell.execute_reply":"2024-03-29T10:31:44.255516Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model = t5_base_model,\n    args = training_args,\n    train_dataset = t5_base_tokenized_data[\"train\"],\n    eval_dataset = t5_base_tokenized_data[\"val\"],\n    tokenizer = t5_base_tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:33:37.746255Z","iopub.execute_input":"2024-03-29T10:33:37.746641Z","iopub.status.idle":"2024-03-29T10:33:37.768943Z","shell.execute_reply.started":"2024-03-29T10:33:37.746613Z","shell.execute_reply":"2024-03-29T10:33:37.767741Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:33:52.562892Z","iopub.execute_input":"2024-03-29T10:33:52.563650Z","iopub.status.idle":"2024-03-29T11:04:20.046201Z","shell.execute_reply.started":"2024-03-29T10:33:52.563618Z","shell.execute_reply":"2024-03-29T11:04:20.045271Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [885/885 30:25, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.450725</td>\n      <td>{'r': 0.1628415189764626, 'p': 0.6634320626529636, 'f': 0.2588926368388458}</td>\n      <td>{'r': 0.07117565265418536, 'p': 0.37584502319170643, 'f': 0.11846411765684098}</td>\n      <td>{'r': 0.1497600295477841, 'p': 0.6116983906095302, 'f': 0.23817615055031585}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.416676</td>\n      <td>{'r': 0.167401705669421, 'p': 0.6765066846887878, 'f': 0.2656676487797007}</td>\n      <td>{'r': 0.0749656884820431, 'p': 0.3914811624198356, 'f': 0.12454612905039124}</td>\n      <td>{'r': 0.15474660702986653, 'p': 0.6263578785512459, 'f': 0.24564630690342165}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.581000</td>\n      <td>1.404616</td>\n      <td>{'r': 0.16809011236165894, 'p': 0.6834468572265822, 'f': 0.26700664848010097}</td>\n      <td>{'r': 0.07567568020110897, 'p': 0.39971589354880954, 'f': 0.12591480599258173}</td>\n      <td>{'r': 0.15541884195389366, 'p': 0.6332211311842105, 'f': 0.24695705663618991}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.581000</td>\n      <td>1.394844</td>\n      <td>{'r': 0.1678356918497007, 'p': 0.6834247020073057, 'f': 0.2666485805808682}</td>\n      <td>{'r': 0.0762194738425002, 'p': 0.40338205726503623, 'f': 0.12683671761161106}</td>\n      <td>{'r': 0.155688883473455, 'p': 0.635313086417593, 'f': 0.24742679487326824}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.581000</td>\n      <td>1.393673</td>\n      <td>{'r': 0.16785097776704277, 'p': 0.683698504249193, 'f': 0.266688874276523}</td>\n      <td>{'r': 0.07615434736587069, 'p': 0.4033418472780176, 'f': 0.12674555284057912}</td>\n      <td>{'r': 0.15581402880410963, 'p': 0.636027570908673, 'f': 0.2476394822238726}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=885, training_loss=1.5368183373057909, metrics={'train_runtime': 1826.9657, 'train_samples_per_second': 7.715, 'train_steps_per_second': 0.484, 'total_flos': 8583261467443200.0, 'train_loss': 1.5368183373057909, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Saving Model","metadata":{}},{"cell_type":"code","source":"# save the model\nmodel_path = \"t5-base-news-sum-fine\"\ntrainer.save_model(model_path)\nt5_base_tokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:05:35.296783Z","iopub.execute_input":"2024-03-29T11:05:35.297547Z","iopub.status.idle":"2024-03-29T11:05:36.864038Z","shell.execute_reply.started":"2024-03-29T11:05:35.297513Z","shell.execute_reply":"2024-03-29T11:05:36.863236Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"('t5-base-news-sum-fine/tokenizer_config.json',\n 't5-base-news-sum-fine/special_tokens_map.json',\n 't5-base-news-sum-fine/spiece.model',\n 't5-base-news-sum-fine/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Inferencing","metadata":{}},{"cell_type":"markdown","source":"### Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/t5-base-news-sum-fine\").to(device)\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/working/t5-base-news-sum-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:06:37.995422Z","iopub.execute_input":"2024-03-29T11:06:37.995869Z","iopub.status.idle":"2024-03-29T11:06:39.172278Z","shell.execute_reply.started":"2024-03-29T11:06:37.995838Z","shell.execute_reply":"2024-03-29T11:06:39.171169Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Create Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nt5_base_summarizer = pipeline(\"summarization\", model = model,tokenizer = tokenizer, device=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:07:48.682396Z","iopub.execute_input":"2024-03-29T11:07:48.683362Z","iopub.status.idle":"2024-03-29T11:07:48.708454Z","shell.execute_reply.started":"2024-03-29T11:07:48.683321Z","shell.execute_reply":"2024-03-29T11:07:48.707530Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Inference on some instances","metadata":{}},{"cell_type":"code","source":"for i in range(3):\n    summary = t5_base_summarizer(test_news['news'].iloc[i])\n    print(\"Reference Summary:- \", test_news['summary'].iloc[i])\n    print(\"\\nGenerated Summary:- \",summary[0]['summary_text'])\n    print(\"==\"*50)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:08:22.665774Z","iopub.execute_input":"2024-03-29T11:08:22.666662Z","iopub.status.idle":"2024-03-29T11:08:28.602699Z","shell.execute_reply.started":"2024-03-29T11:08:22.666630Z","shell.execute_reply":"2024-03-29T11:08:28.601819Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Reference Summary:-  the indian space research organisation isro is set to launch record 103 satellites in a single flight in february first week . as many as 100 of the satellites to be launched are from foreign nations . earlier isro had said it will launch 83 satellites but the launch got delayed due to the addition of more satellites an official said .\n\nGenerated Summary:-  the indian space research organisation isro is all set to launch a record 103 satellites in one go using its workhorse pslvc37 in the first week of february . we are making a century by launching over 100 satellites at one go said s somnath director of the liquid propulsion systems centre . the launch was delayed by a week with the addition of 20 more foreign satellites .\n====================================================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 197. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\n","output_type":"stream"},{"name":"stdout","text":"Reference Summary:-  women and children will be allowed to use toilet facilities at hotels and restaurants including fivestars in south delhi for free from may 1 . security concerns coupled with the fact that some restaurants and bars dont allow single males made us keep men out of the scheme for now national restaurants association head riaz amlani said .\n\nGenerated Summary:-  women and children will no longer have to go looking for public washrooms to relieve themselves after a long day of shopping at south delhi markets . simply walking into the nearest restaurant and conveying their need to the staff will make posh toilets accessible to them completely free of cost . however men have been kept of out of the scheme due to privacy issues cited by various hotel associations .\n====================================================================================================\n\nReference Summary:-  an image of a pregnant us president donald trump being hugged by russian president vladimir putin from behind was projected on buildings in new york along with lovethroughhate . the image was a part of an ad campaign by the dating app hater . were just trying to make people laugh . through humour hate can turn into love the apps representatives said .\n\nGenerated Summary:-  the image of russian president vladimir putin embracing us president donald trump from behind was projected on some buildings in new york and neighbourhoods williamsburg and chelsea with the hashtag lovethroughhate . hater app matches potential dates based on the things people mutually hate .\n====================================================================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing on Test Set","metadata":{}},{"cell_type":"code","source":"def generate_summary_t5(text):\n    summary = t5_base_summarizer(text)\n    return summary[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:09:58.906763Z","iopub.execute_input":"2024-03-29T11:09:58.907532Z","iopub.status.idle":"2024-03-29T11:09:58.912133Z","shell.execute_reply.started":"2024-03-29T11:09:58.907501Z","shell.execute_reply":"2024-03-29T11:09:58.911053Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"test_news['t5_base_summary'] = test_news['news'].apply(lambda x: generate_summary_t5(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:10:15.794917Z","iopub.execute_input":"2024-03-29T11:10:15.795561Z","iopub.status.idle":"2024-03-29T11:23:20.645676Z","shell.execute_reply.started":"2024-03-29T11:10:15.795529Z","shell.execute_reply":"2024-03-29T11:23:20.644601Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 197. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\nYour max_length is set to 200, but your input_length is only 115. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nYour max_length is set to 200, but your input_length is only 170. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\nYour max_length is set to 200, but your input_length is only 142. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\nYour max_length is set to 200, but your input_length is only 140. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\nYour max_length is set to 200, but your input_length is only 68. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\nYour max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\nYour max_length is set to 200, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\nYour max_length is set to 200, but your input_length is only 177. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=88)\nYour max_length is set to 200, but your input_length is only 106. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=53)\nYour max_length is set to 200, but your input_length is only 182. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\nYour max_length is set to 200, but your input_length is only 175. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 199. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\nYour max_length is set to 200, but your input_length is only 198. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\nYour max_length is set to 200, but your input_length is only 196. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\nYour max_length is set to 200, but your input_length is only 164. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=82)\nYour max_length is set to 200, but your input_length is only 144. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\nYour max_length is set to 200, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\nYour max_length is set to 200, but your input_length is only 56. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\nYour max_length is set to 200, but your input_length is only 130. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\nYour max_length is set to 200, but your input_length is only 175. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 174. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\nYour max_length is set to 200, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\nYour max_length is set to 200, but your input_length is only 151. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\nYour max_length is set to 200, but your input_length is only 154. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\nYour max_length is set to 200, but your input_length is only 160. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=80)\nYour max_length is set to 200, but your input_length is only 189. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=94)\nYour max_length is set to 200, but your input_length is only 63. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\nYour max_length is set to 200, but your input_length is only 172. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\nYour max_length is set to 200, but your input_length is only 155. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\nYour max_length is set to 200, but your input_length is only 157. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=78)\nYour max_length is set to 200, but your input_length is only 190. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\nYour max_length is set to 200, but your input_length is only 119. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\nYour max_length is set to 200, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\nYour max_length is set to 200, but your input_length is only 176. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=88)\nYour max_length is set to 200, but your input_length is only 89. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\nYour max_length is set to 200, but your input_length is only 138. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\nYour max_length is set to 200, but your input_length is only 55. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\nYour max_length is set to 200, but your input_length is only 180. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\nYour max_length is set to 200, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\nYour max_length is set to 200, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:24:05.766963Z","iopub.execute_input":"2024-03-29T11:24:05.767370Z","iopub.status.idle":"2024-03-29T11:24:05.783206Z","shell.execute_reply.started":"2024-03-29T11:24:05.767336Z","shell.execute_reply":"2024-03-29T11:24:05.782201Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"                                                summary  \\\n1492  the indian space research organisation isro is...   \n3070  women and children will be allowed to use toil...   \n895   an image of a pregnant us president donald tru...   \n3867  banking operations across the country came to ...   \n3707  indian national congress could manage to win o...   \n...                                                 ...   \n1350  sasi gangadharan a semiparalysed man from kera...   \n1384  usbased researchers have identified that the h...   \n2960  aap mla kapil mishra who was sacked on saturda...   \n1119  a child rights commission in tamil nadu has re...   \n2348  the indian railways has decided to allow forei...   \n\n                                                   news  \\\n1492  summarize: the indian space research organisat...   \n3070  summarize: starting monday women and children ...   \n895   summarize: the image of russian president vlad...   \n3867  summarize: banking operations across the count...   \n3707  summarize: six out of 10 assembly seats in ame...   \n...                                                 ...   \n1350  summarize: eighteen years ago sasi gangadharan...   \n1384  summarize: washington jan 10 pti the human app...   \n2960  summarize: rumblings in the aam aadmi party co...   \n1119  summarize: after a complaint filed by a child ...   \n2348  summarize: new delhi jul 3 pti now foreign tou...   \n\n                                       t5_small_summary  \\\n1492  the indian space research organisation isro is...   \n3070  south delhi municipal corporation sdmc commiss...   \n895   the image of russian president vladimir putin ...   \n3867  banking operations across the country came to ...   \n3707  six out of 10 assembly seats in amethi and rae...   \n...                                                 ...   \n1350  sasi gangadharan a coconut tree climber from t...   \n1384  the human appendix a narrow pouch that project...   \n2960  delhi water minister kapil mishra has been sac...   \n1119  tamil nadu commission for protection of child ...   \n2348  new delhi jul 3 pti now foreign tourists can b...   \n\n                                        t5_base_summary  \n1492  the indian space research organisation isro is...  \n3070  women and children will no longer have to go l...  \n895   the image of russian president vladimir putin ...  \n3867  10 lakh bankers staged a strike against the go...  \n3707  six out of 10 assembly seats in amethi and rae...  \n...                                                 ...  \n1350  sasi gangadharan a coconut tree climber from t...  \n1384  the human appendix a narrow pouch that project...  \n2960  sacked delhi water minister kapil mishra has m...  \n1119  tamil nadu commission for protection of child ...  \n2348  the indian railways has announced that foreign...  \n\n[392 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>news</th>\n      <th>t5_small_summary</th>\n      <th>t5_base_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1492</th>\n      <td>the indian space research organisation isro is...</td>\n      <td>summarize: the indian space research organisat...</td>\n      <td>the indian space research organisation isro is...</td>\n      <td>the indian space research organisation isro is...</td>\n    </tr>\n    <tr>\n      <th>3070</th>\n      <td>women and children will be allowed to use toil...</td>\n      <td>summarize: starting monday women and children ...</td>\n      <td>south delhi municipal corporation sdmc commiss...</td>\n      <td>women and children will no longer have to go l...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>an image of a pregnant us president donald tru...</td>\n      <td>summarize: the image of russian president vlad...</td>\n      <td>the image of russian president vladimir putin ...</td>\n      <td>the image of russian president vladimir putin ...</td>\n    </tr>\n    <tr>\n      <th>3867</th>\n      <td>banking operations across the country came to ...</td>\n      <td>summarize: banking operations across the count...</td>\n      <td>banking operations across the country came to ...</td>\n      <td>10 lakh bankers staged a strike against the go...</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>indian national congress could manage to win o...</td>\n      <td>summarize: six out of 10 assembly seats in ame...</td>\n      <td>six out of 10 assembly seats in amethi and rae...</td>\n      <td>six out of 10 assembly seats in amethi and rae...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>sasi gangadharan a semiparalysed man from kera...</td>\n      <td>summarize: eighteen years ago sasi gangadharan...</td>\n      <td>sasi gangadharan a coconut tree climber from t...</td>\n      <td>sasi gangadharan a coconut tree climber from t...</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>usbased researchers have identified that the h...</td>\n      <td>summarize: washington jan 10 pti the human app...</td>\n      <td>the human appendix a narrow pouch that project...</td>\n      <td>the human appendix a narrow pouch that project...</td>\n    </tr>\n    <tr>\n      <th>2960</th>\n      <td>aap mla kapil mishra who was sacked on saturda...</td>\n      <td>summarize: rumblings in the aam aadmi party co...</td>\n      <td>delhi water minister kapil mishra has been sac...</td>\n      <td>sacked delhi water minister kapil mishra has m...</td>\n    </tr>\n    <tr>\n      <th>1119</th>\n      <td>a child rights commission in tamil nadu has re...</td>\n      <td>summarize: after a complaint filed by a child ...</td>\n      <td>tamil nadu commission for protection of child ...</td>\n      <td>tamil nadu commission for protection of child ...</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>the indian railways has decided to allow forei...</td>\n      <td>summarize: new delhi jul 3 pti now foreign tou...</td>\n      <td>new delhi jul 3 pti now foreign tourists can b...</td>\n      <td>the indian railways has announced that foreign...</td>\n    </tr>\n  </tbody>\n</table>\n<p>392 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate on Test Data","metadata":{}},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef evaluate_test_summaries(news_data):\n    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n    rouge_scores = []\n\n    for idx, row in test_news.iterrows():\n        scores = scorer.score(target=row['summary'], prediction=row['t5_base_summary'])\n        rouge_scores.append(scores)\n\n    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n\n    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n\n    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n\n    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:25:07.902441Z","iopub.execute_input":"2024-03-29T11:25:07.903283Z","iopub.status.idle":"2024-03-29T11:25:07.914604Z","shell.execute_reply.started":"2024-03-29T11:25:07.903252Z","shell.execute_reply":"2024-03-29T11:25:07.913532Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(\"For T5-Base (FineTuned):- \")\nprint(\"\\nEvaluation for the test summary: \\n\")\nevaluate_test_summaries(test_news)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:26:11.866713Z","iopub.execute_input":"2024-03-29T11:26:11.867832Z","iopub.status.idle":"2024-03-29T11:26:12.911058Z","shell.execute_reply.started":"2024-03-29T11:26:11.867796Z","shell.execute_reply":"2024-03-29T11:26:12.910135Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"For T5-Base (FineTuned):- \n\nEvaluation for the test summary: \n\nAverage ROUGE-1 Precision:  0.4912017558071222\nAverage ROUGE-1 Recall:  0.47417111536210593\nAverage ROUGE-1 F1-Score:  0.47822674414523353\nAverage ROUGE-2 Precision:  0.2626294725939422\nAverage ROUGE-2 Recall:  0.25308497289355675\nAverage ROUGE-2 F1-Score:  0.25524545642826096\nAverage ROUGE-L Precision:  0.3699302665876597\nAverage ROUGE-L Recall:  0.35630072322131695\nAverage ROUGE-L F1-Score:  0.35959601725547086\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download Saved Model","metadata":{}},{"cell_type":"markdown","source":"### Create Zip File","metadata":{}},{"cell_type":"code","source":"import shutil\n# Define the directory containing your model files\nmodel_directory = \"/kaggle/working/t5-base-news-sum-fine\"\n# Define the name for your zip file\nzip_file_name = \"t5-base-news-sum-fine\"\n# Create a zip file containing the model directory\nshutil.make_archive(zip_file_name, 'zip', model_directory)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:32:12.116710Z","iopub.execute_input":"2024-03-29T11:32:12.117119Z","iopub.status.idle":"2024-03-29T11:35:52.278493Z","shell.execute_reply.started":"2024-03-29T11:32:12.117090Z","shell.execute_reply":"2024-03-29T11:35:52.277436Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/t5-base-news-sum-fine.zip'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Create Downloadable Link","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:37:07.531929Z","iopub.execute_input":"2024-03-29T11:37:07.532811Z","iopub.status.idle":"2024-03-29T11:37:08.608586Z","shell.execute_reply.started":"2024-03-29T11:37:07.532778Z","shell.execute_reply":"2024-03-29T11:37:08.607294Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"filtered_news_data.csv\t   t5-small-news-sum-fine      train_news.csv\nt5-base-news-sum-fine\t   t5-small-news-sum-fine.zip\nt5-base-news-sum-fine.zip  test_news.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r't5-base-news-sum-fine.zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:37:33.324872Z","iopub.execute_input":"2024-03-29T11:37:33.325281Z","iopub.status.idle":"2024-03-29T11:37:33.332439Z","shell.execute_reply.started":"2024-03-29T11:37:33.325252Z","shell.execute_reply":"2024-03-29T11:37:33.331603Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/t5-base-news-sum-fine.zip","text/html":"<a href='t5-base-news-sum-fine.zip' target='_blank'>t5-base-news-sum-fine.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Empty Cache Memory","metadata":{}},{"cell_type":"code","source":"# Free up memory\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:55:08.546134Z","iopub.execute_input":"2024-03-29T11:55:08.546972Z","iopub.status.idle":"2024-03-29T11:55:09.252750Z","shell.execute_reply.started":"2024-03-29T11:55:08.546939Z","shell.execute_reply":"2024-03-29T11:55:09.251560Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# BART Base Modeling","metadata":{}},{"cell_type":"markdown","source":"## Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\nbart_base_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base').to(device)\nbart_base_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:59:29.553925Z","iopub.execute_input":"2024-03-29T11:59:29.554894Z","iopub.status.idle":"2024-03-29T11:59:31.194624Z","shell.execute_reply.started":"2024-03-29T11:59:29.554857Z","shell.execute_reply":"2024-03-29T11:59:31.193499Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(data):\n    inputs = data[\"news\"]\n    model_inputs = bart_base_tokenizer(inputs, max_length=512, truncation=True)\n    labels = bart_base_tokenizer(text_target=data[\"summary\"], max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:01:04.254603Z","iopub.execute_input":"2024-03-29T12:01:04.255361Z","iopub.status.idle":"2024-03-29T12:01:04.260790Z","shell.execute_reply.started":"2024-03-29T12:01:04.255327Z","shell.execute_reply":"2024-03-29T12:01:04.259916Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"bart_base_tokenized_data = train_val_dataset.map(prepare_dataset, batched=True)\nbart_base_tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:01:47.348585Z","iopub.execute_input":"2024-03-29T12:01:47.348991Z","iopub.status.idle":"2024-03-29T12:02:05.515214Z","shell.execute_reply.started":"2024-03-29T12:01:47.348964Z","shell.execute_reply":"2024-03-29T12:02:05.514248Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b5efa21ec643adafd6385c63739765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0409e0e9b14169814effa2661b674b"}},"metadata":{}},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2819\n    })\n    val: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 705\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer= bart_base_tokenizer, model=bart_base_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:03:16.909981Z","iopub.execute_input":"2024-03-29T12:03:16.910382Z","iopub.status.idle":"2024-03-29T12:03:16.915655Z","shell.execute_reply.started":"2024-03-29T12:03:16.910351Z","shell.execute_reply":"2024-03-29T12:03:16.914533Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Compute Metrics","metadata":{}},{"cell_type":"code","source":"from rouge import Rouge\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = bart_base_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, bart_base_tokenizer.pad_token_id)\n    decoded_labels = bart_base_tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = Rouge().get_scores(decoded_preds, decoded_labels, avg=True, ignore_empty=True)\n\n    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    # result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:04:15.102047Z","iopub.execute_input":"2024-03-29T12:04:15.102748Z","iopub.status.idle":"2024-03-29T12:04:15.109916Z","shell.execute_reply.started":"2024-03-29T12:04:15.102713Z","shell.execute_reply":"2024-03-29T12:04:15.108687Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"## Setting Training Argumenets","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"bart-base-news-sum-fine\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:05:11.380634Z","iopub.execute_input":"2024-03-29T12:05:11.381652Z","iopub.status.idle":"2024-03-29T12:05:11.388668Z","shell.execute_reply.started":"2024-03-29T12:05:11.381607Z","shell.execute_reply":"2024-03-29T12:05:11.387676Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model = bart_base_model,\n    args = training_args,\n    train_dataset = bart_base_tokenized_data[\"train\"],\n    eval_dataset = bart_base_tokenized_data[\"val\"],\n    tokenizer = bart_base_tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:06:20.882320Z","iopub.execute_input":"2024-03-29T12:06:20.883212Z","iopub.status.idle":"2024-03-29T12:06:20.903067Z","shell.execute_reply.started":"2024-03-29T12:06:20.883176Z","shell.execute_reply":"2024-03-29T12:06:20.902066Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:06:32.355447Z","iopub.execute_input":"2024-03-29T12:06:32.356439Z","iopub.status.idle":"2024-03-29T12:23:01.100168Z","shell.execute_reply.started":"2024-03-29T12:06:32.356408Z","shell.execute_reply":"2024-03-29T12:23:01.099238Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [885/885 16:27, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.793528</td>\n      <td>{'r': 0.17877187503616232, 'p': 0.6633735408891868, 'f': 0.27982430999463015}</td>\n      <td>{'r': 0.0829149543039276, 'p': 0.3943548768016855, 'f': 0.1361744735159913}</td>\n      <td>{'r': 0.16620701152975154, 'p': 0.6180734767249171, 'f': 0.26027416255917174}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.739008</td>\n      <td>{'r': 0.18265433424218153, 'p': 0.6780211738847544, 'f': 0.2859900037578004}</td>\n      <td>{'r': 0.08602156109003656, 'p': 0.40866643600686176, 'f': 0.14128906702050947}</td>\n      <td>{'r': 0.17033086390546642, 'p': 0.6333834882958795, 'f': 0.2667910912576665}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.014600</td>\n      <td>1.716352</td>\n      <td>{'r': 0.18433033008073849, 'p': 0.6831720305374879, 'f': 0.2884914537446572}</td>\n      <td>{'r': 0.08732257963721683, 'p': 0.41543694485183835, 'f': 0.14345128232652557}</td>\n      <td>{'r': 0.17161168434433222, 'p': 0.6368711952535485, 'f': 0.26865579090312675}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.014600</td>\n      <td>1.714038</td>\n      <td>{'r': 0.1841942211796001, 'p': 0.6849368068078965, 'f': 0.2885075271700781}</td>\n      <td>{'r': 0.08774068854957644, 'p': 0.4188095218414369, 'f': 0.1442362018384003}</td>\n      <td>{'r': 0.17148308222547035, 'p': 0.6386522675164735, 'f': 0.26868306047593005}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.014600</td>\n      <td>1.708896</td>\n      <td>{'r': 0.18391563528804872, 'p': 0.6831923261460189, 'f': 0.2880104927303693}</td>\n      <td>{'r': 0.08708510728351558, 'p': 0.41517203049117946, 'f': 0.14312410321474003}</td>\n      <td>{'r': 0.1709196568193276, 'p': 0.6360569591952574, 'f': 0.26776069266995317}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=885, training_loss=1.8980897030587924, metrics={'train_runtime': 988.1505, 'train_samples_per_second': 14.264, 'train_steps_per_second': 0.896, 'total_flos': 4291144177582080.0, 'train_loss': 1.8980897030587924, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Saving Model","metadata":{}},{"cell_type":"code","source":"# save the model\nmodel_path = \"bart-base-news-sum-fine\"\ntrainer.save_model(model_path)\nbart_base_tokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:25:41.961899Z","iopub.execute_input":"2024-03-29T12:25:41.962726Z","iopub.status.idle":"2024-03-29T12:25:43.173655Z","shell.execute_reply.started":"2024-03-29T12:25:41.962691Z","shell.execute_reply":"2024-03-29T12:25:43.172625Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"('bart-base-news-sum-fine/tokenizer_config.json',\n 'bart-base-news-sum-fine/special_tokens_map.json',\n 'bart-base-news-sum-fine/vocab.json',\n 'bart-base-news-sum-fine/merges.txt',\n 'bart-base-news-sum-fine/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Inferencing","metadata":{}},{"cell_type":"markdown","source":"### Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nmodel = BartForConditionalGeneration.from_pretrained(\"/kaggle/working/bart-base-news-sum-fine\").to(device)\ntokenizer = BartTokenizer.from_pretrained(\"/kaggle/working/bart-base-news-sum-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:26:59.381225Z","iopub.execute_input":"2024-03-29T12:26:59.381699Z","iopub.status.idle":"2024-03-29T12:27:00.583008Z","shell.execute_reply.started":"2024-03-29T12:26:59.381667Z","shell.execute_reply":"2024-03-29T12:27:00.581744Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"### Create pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nbart_base_summarizer = pipeline(\"summarization\", model = model,tokenizer = tokenizer, device=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:28:25.653735Z","iopub.execute_input":"2024-03-29T12:28:25.654136Z","iopub.status.idle":"2024-03-29T12:28:25.677692Z","shell.execute_reply.started":"2024-03-29T12:28:25.654109Z","shell.execute_reply":"2024-03-29T12:28:25.676915Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"### Inference on some instance","metadata":{}},{"cell_type":"code","source":"for i in range(3):\n    summary = bart_base_summarizer(test_news['news'].iloc[i])\n    print(\"Reference Summary:- \", test_news['summary'].iloc[i])\n    print(\"\\nGenerated Summary:- \",summary[0]['summary_text'])\n    print(\"==\"*50)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:29:06.201698Z","iopub.execute_input":"2024-03-29T12:29:06.202448Z","iopub.status.idle":"2024-03-29T12:29:08.522524Z","shell.execute_reply.started":"2024-03-29T12:29:06.202422Z","shell.execute_reply":"2024-03-29T12:29:08.521419Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Reference Summary:-  the indian space research organisation isro is set to launch record 103 satellites in a single flight in february first week . as many as 100 of the satellites to be launched are from foreign nations . earlier isro had said it will launch 83 satellites but the launch got delayed due to the addition of more satellites an official said .\n\nGenerated Summary:-  the indian space research organisation isro is set to launch 103 satellites in one go using its workhorse pslvc37 in the first week of february . as many as 100 of the satellites set for launch this year belong to foreign nations including the united states and germany . we are making a century by launching over 100 satellites at one go said s somnath .\n====================================================================================================\n\nReference Summary:-  women and children will be allowed to use toilet facilities at hotels and restaurants including fivestars in south delhi for free from may 1 . security concerns coupled with the fact that some restaurants and bars dont allow single males made us keep men out of the scheme for now national restaurants association head riaz amlani said .\n\nGenerated Summary:-  south delhi municipal corporation sdmc commissioner puneet kumar goel on monday announced that women and children will no longer have to go looking for public washrooms to relieve themselves after a long day of shopping at south delhi markets . simply walking into the nearest restaurant and conveying their need to the staff will make posh toilets accessible to them completely free of cost he added .\n====================================================================================================\n\nReference Summary:-  an image of a pregnant us president donald trump being hugged by russian president vladimir putin from behind was projected on buildings in new york along with lovethroughhate . the image was a part of an ad campaign by the dating app hater . were just trying to make people laugh . through humour hate can turn into love the apps representatives said .\n\nGenerated Summary:-  the image of russian president vladimir putin embracing us president donald trump from behind was projected on some buildings in new york and neighbourhoods williamsburg and chelsea with hashtag lovethroughhate . more than being a part of an antitrump resistance which has lingered since he started campaigning for the us president post this was a publicity stunt by a dating app called hater . hater matches potential dates based on the things people mutually hate .\n====================================================================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing on Test Set","metadata":{}},{"cell_type":"code","source":"def generate_summary_bart_base(text):\n    summary = bart_base_summarizer(text)\n    return summary[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:30:48.537993Z","iopub.execute_input":"2024-03-29T12:30:48.538998Z","iopub.status.idle":"2024-03-29T12:30:48.543489Z","shell.execute_reply.started":"2024-03-29T12:30:48.538962Z","shell.execute_reply":"2024-03-29T12:30:48.542520Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"test_news['bart_base_summary'] = test_news['news'].apply(lambda x: generate_summary_bart_base(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:30:53.820543Z","iopub.execute_input":"2024-03-29T12:30:53.821201Z","iopub.status.idle":"2024-03-29T12:35:57.809843Z","shell.execute_reply.started":"2024-03-29T12:30:53.821173Z","shell.execute_reply":"2024-03-29T12:35:57.808915Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stderr","text":"Your max_length is set to 128, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nYour max_length is set to 128, but your input_length is only 112. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\nYour max_length is set to 128, but your input_length is only 60. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\nYour max_length is set to 128, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\nYour max_length is set to 128, but your input_length is only 81. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\nYour max_length is set to 128, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\nYour max_length is set to 128, but your input_length is only 127. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\nYour max_length is set to 128, but your input_length is only 116. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\nYour max_length is set to 128, but your input_length is only 42. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\nYour max_length is set to 128, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_news","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:40:06.897260Z","iopub.execute_input":"2024-03-29T12:40:06.898154Z","iopub.status.idle":"2024-03-29T12:40:06.913284Z","shell.execute_reply.started":"2024-03-29T12:40:06.898121Z","shell.execute_reply":"2024-03-29T12:40:06.911995Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"                                                summary  \\\n1492  the indian space research organisation isro is...   \n3070  women and children will be allowed to use toil...   \n895   an image of a pregnant us president donald tru...   \n3867  banking operations across the country came to ...   \n3707  indian national congress could manage to win o...   \n...                                                 ...   \n1350  sasi gangadharan a semiparalysed man from kera...   \n1384  usbased researchers have identified that the h...   \n2960  aap mla kapil mishra who was sacked on saturda...   \n1119  a child rights commission in tamil nadu has re...   \n2348  the indian railways has decided to allow forei...   \n\n                                                   news  \\\n1492  summarize: the indian space research organisat...   \n3070  summarize: starting monday women and children ...   \n895   summarize: the image of russian president vlad...   \n3867  summarize: banking operations across the count...   \n3707  summarize: six out of 10 assembly seats in ame...   \n...                                                 ...   \n1350  summarize: eighteen years ago sasi gangadharan...   \n1384  summarize: washington jan 10 pti the human app...   \n2960  summarize: rumblings in the aam aadmi party co...   \n1119  summarize: after a complaint filed by a child ...   \n2348  summarize: new delhi jul 3 pti now foreign tou...   \n\n                                       t5_small_summary  \\\n1492  the indian space research organisation isro is...   \n3070  south delhi municipal corporation sdmc commiss...   \n895   the image of russian president vladimir putin ...   \n3867  banking operations across the country came to ...   \n3707  six out of 10 assembly seats in amethi and rae...   \n...                                                 ...   \n1350  sasi gangadharan a coconut tree climber from t...   \n1384  the human appendix a narrow pouch that project...   \n2960  delhi water minister kapil mishra has been sac...   \n1119  tamil nadu commission for protection of child ...   \n2348  new delhi jul 3 pti now foreign tourists can b...   \n\n                                        t5_base_summary  \\\n1492  the indian space research organisation isro is...   \n3070  women and children will no longer have to go l...   \n895   the image of russian president vladimir putin ...   \n3867  10 lakh bankers staged a strike against the go...   \n3707  six out of 10 assembly seats in amethi and rae...   \n...                                                 ...   \n1350  sasi gangadharan a coconut tree climber from t...   \n1384  the human appendix a narrow pouch that project...   \n2960  sacked delhi water minister kapil mishra has m...   \n1119  tamil nadu commission for protection of child ...   \n2348  the indian railways has announced that foreign...   \n\n                                      bart_base_summary  \n1492  the indian space research organisation isro is...  \n3070  south delhi municipal corporation sdmc commiss...  \n895   the image of russian president vladimir putin ...  \n3867  banking operations across the country came to ...  \n3707  bjp president amit shah on monday said that si...  \n...                                                 ...  \n1350  a coconut tree climber from keralas thiruvanan...  \n1384  a new study has found that the human appendix ...  \n2960  former delhi water minister kapil mishra has m...  \n1119  the tamil nadu commission for protection of ch...  \n2348  foreign tourists can book train tickets 360 da...  \n\n[392 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>news</th>\n      <th>t5_small_summary</th>\n      <th>t5_base_summary</th>\n      <th>bart_base_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1492</th>\n      <td>the indian space research organisation isro is...</td>\n      <td>summarize: the indian space research organisat...</td>\n      <td>the indian space research organisation isro is...</td>\n      <td>the indian space research organisation isro is...</td>\n      <td>the indian space research organisation isro is...</td>\n    </tr>\n    <tr>\n      <th>3070</th>\n      <td>women and children will be allowed to use toil...</td>\n      <td>summarize: starting monday women and children ...</td>\n      <td>south delhi municipal corporation sdmc commiss...</td>\n      <td>women and children will no longer have to go l...</td>\n      <td>south delhi municipal corporation sdmc commiss...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>an image of a pregnant us president donald tru...</td>\n      <td>summarize: the image of russian president vlad...</td>\n      <td>the image of russian president vladimir putin ...</td>\n      <td>the image of russian president vladimir putin ...</td>\n      <td>the image of russian president vladimir putin ...</td>\n    </tr>\n    <tr>\n      <th>3867</th>\n      <td>banking operations across the country came to ...</td>\n      <td>summarize: banking operations across the count...</td>\n      <td>banking operations across the country came to ...</td>\n      <td>10 lakh bankers staged a strike against the go...</td>\n      <td>banking operations across the country came to ...</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>indian national congress could manage to win o...</td>\n      <td>summarize: six out of 10 assembly seats in ame...</td>\n      <td>six out of 10 assembly seats in amethi and rae...</td>\n      <td>six out of 10 assembly seats in amethi and rae...</td>\n      <td>bjp president amit shah on monday said that si...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>sasi gangadharan a semiparalysed man from kera...</td>\n      <td>summarize: eighteen years ago sasi gangadharan...</td>\n      <td>sasi gangadharan a coconut tree climber from t...</td>\n      <td>sasi gangadharan a coconut tree climber from t...</td>\n      <td>a coconut tree climber from keralas thiruvanan...</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>usbased researchers have identified that the h...</td>\n      <td>summarize: washington jan 10 pti the human app...</td>\n      <td>the human appendix a narrow pouch that project...</td>\n      <td>the human appendix a narrow pouch that project...</td>\n      <td>a new study has found that the human appendix ...</td>\n    </tr>\n    <tr>\n      <th>2960</th>\n      <td>aap mla kapil mishra who was sacked on saturda...</td>\n      <td>summarize: rumblings in the aam aadmi party co...</td>\n      <td>delhi water minister kapil mishra has been sac...</td>\n      <td>sacked delhi water minister kapil mishra has m...</td>\n      <td>former delhi water minister kapil mishra has m...</td>\n    </tr>\n    <tr>\n      <th>1119</th>\n      <td>a child rights commission in tamil nadu has re...</td>\n      <td>summarize: after a complaint filed by a child ...</td>\n      <td>tamil nadu commission for protection of child ...</td>\n      <td>tamil nadu commission for protection of child ...</td>\n      <td>the tamil nadu commission for protection of ch...</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>the indian railways has decided to allow forei...</td>\n      <td>summarize: new delhi jul 3 pti now foreign tou...</td>\n      <td>new delhi jul 3 pti now foreign tourists can b...</td>\n      <td>the indian railways has announced that foreign...</td>\n      <td>foreign tourists can book train tickets 360 da...</td>\n    </tr>\n  </tbody>\n</table>\n<p>392 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate on Test Data","metadata":{}},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef evaluate_test_summaries(news_data):\n    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n    rouge_scores = []\n\n    for idx, row in test_news.iterrows():\n        scores = scorer.score(target=row['summary'], prediction=row['bart_base_summary'])\n        rouge_scores.append(scores)\n\n    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n\n    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n\n    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n\n    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:41:00.387468Z","iopub.execute_input":"2024-03-29T12:41:00.387851Z","iopub.status.idle":"2024-03-29T12:41:00.399407Z","shell.execute_reply.started":"2024-03-29T12:41:00.387824Z","shell.execute_reply":"2024-03-29T12:41:00.398358Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"print(\"For Bart-Base (FineTuned):- \")\nprint(\"\\nEvaluation for the test summary: \\n\")\nevaluate_test_summaries(test_news)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:41:24.471644Z","iopub.execute_input":"2024-03-29T12:41:24.472267Z","iopub.status.idle":"2024-03-29T12:41:25.574886Z","shell.execute_reply.started":"2024-03-29T12:41:24.472238Z","shell.execute_reply":"2024-03-29T12:41:25.573867Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"For Bart-Base (FineTuned):- \n\nEvaluation for the test summary: \n\nAverage ROUGE-1 Precision:  0.47284096062155256\nAverage ROUGE-1 Recall:  0.49304117074314413\nAverage ROUGE-1 F1-Score:  0.47979170748525635\nAverage ROUGE-2 Precision:  0.2579776674100123\nAverage ROUGE-2 Recall:  0.2697483137697911\nAverage ROUGE-2 F1-Score:  0.2621123065377172\nAverage ROUGE-L Precision:  0.3548961679574369\nAverage ROUGE-L Recall:  0.3697732336015233\nAverage ROUGE-L F1-Score:  0.35998367685178156\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download Saved Model","metadata":{}},{"cell_type":"markdown","source":"### Create Zip File","metadata":{}},{"cell_type":"code","source":"import shutil\n# Define the directory containing your model files\nmodel_directory = \"/kaggle/working/bart-base-news-sum-fine\"\n# Define the name for your zip file\nzip_file_name = \"bart-base-news-sum-fine\"\n# Create a zip file containing the model directory\nshutil.make_archive(zip_file_name, 'zip', model_directory)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:42:23.122157Z","iopub.execute_input":"2024-03-29T12:42:23.122886Z","iopub.status.idle":"2024-03-29T12:44:33.436966Z","shell.execute_reply.started":"2024-03-29T12:42:23.122854Z","shell.execute_reply":"2024-03-29T12:44:33.435991Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/bart-base-news-sum-fine.zip'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Generate Downloadable Link","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:45:03.057553Z","iopub.execute_input":"2024-03-29T12:45:03.057934Z","iopub.status.idle":"2024-03-29T12:45:04.176847Z","shell.execute_reply.started":"2024-03-29T12:45:03.057906Z","shell.execute_reply":"2024-03-29T12:45:04.175441Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"bart-base-news-sum-fine      t5-small-news-sum-fine\nbart-base-news-sum-fine.zip  t5-small-news-sum-fine.zip\nfiltered_news_data.csv\t     test_news.csv\nt5-base-news-sum-fine\t     train_news.csv\nt5-base-news-sum-fine.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'bart-base-news-sum-fine.zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:45:20.798274Z","iopub.execute_input":"2024-03-29T12:45:20.798698Z","iopub.status.idle":"2024-03-29T12:45:20.806273Z","shell.execute_reply.started":"2024-03-29T12:45:20.798667Z","shell.execute_reply":"2024-03-29T12:45:20.805187Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/bart-base-news-sum-fine.zip","text/html":"<a href='bart-base-news-sum-fine.zip' target='_blank'>bart-base-news-sum-fine.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Empty Cache Memory","metadata":{}},{"cell_type":"code","source":"# Free up memory\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:58:06.522329Z","iopub.execute_input":"2024-03-29T12:58:06.523300Z","iopub.status.idle":"2024-03-29T12:58:06.764947Z","shell.execute_reply.started":"2024-03-29T12:58:06.523267Z","shell.execute_reply":"2024-03-29T12:58:06.763832Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"# BART Large Modeling","metadata":{}},{"cell_type":"markdown","source":"## Loading Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\nbart_large_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\nbart_large_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:58:22.989138Z","iopub.execute_input":"2024-03-29T12:58:22.989818Z","iopub.status.idle":"2024-03-29T12:58:32.780633Z","shell.execute_reply.started":"2024-03-29T12:58:22.989780Z","shell.execute_reply":"2024-03-29T12:58:32.779655Z"},"trusted":true},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1afcb7417a34db3bb6013b72fd81194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098ddeaffa9b4d56ad8bc2395a266df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47595112b3434074bee019a7280c5e85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b02e27f151f49d5b09b98c4e7bc625b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf87ddd2476f42f69ba9b70af7457d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e29e24f281047198ad5ad53550d314f"}},"metadata":{}}]},{"cell_type":"code","source":"def prepare_dataset(data):\n    inputs = data[\"news\"]\n    model_inputs = bart_large_tokenizer(inputs, max_length=512, truncation=True)\n    labels = bart_large_tokenizer(text_target=data[\"summary\"], max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:58:39.644690Z","iopub.execute_input":"2024-03-29T12:58:39.645567Z","iopub.status.idle":"2024-03-29T12:58:39.650889Z","shell.execute_reply.started":"2024-03-29T12:58:39.645524Z","shell.execute_reply":"2024-03-29T12:58:39.649968Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"bart_large_tokenized_data = train_val_dataset.map(prepare_dataset, batched=True)\nbart_large_tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:58:43.879589Z","iopub.execute_input":"2024-03-29T12:58:43.880402Z","iopub.status.idle":"2024-03-29T12:59:01.720984Z","shell.execute_reply.started":"2024-03-29T12:58:43.880371Z","shell.execute_reply":"2024-03-29T12:59:01.720045Z"},"trusted":true},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44e9677b89ce4358a58841aaa77eeed2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db53b3cad89435db158b6a025a48dcb"}},"metadata":{}},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2819\n    })\n    val: Dataset({\n        features: ['summary', 'news', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 705\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\ndata_collator = DataCollatorForSeq2Seq(tokenizer= bart_large_tokenizer, model=bart_large_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:59:05.771535Z","iopub.execute_input":"2024-03-29T12:59:05.772377Z","iopub.status.idle":"2024-03-29T12:59:05.777170Z","shell.execute_reply.started":"2024-03-29T12:59:05.772345Z","shell.execute_reply":"2024-03-29T12:59:05.776006Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"## Compute Metrics","metadata":{}},{"cell_type":"code","source":"from rouge import Rouge\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = bart_large_tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, bart_large_tokenizer.pad_token_id)\n    decoded_labels = bart_large_tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = Rouge().get_scores(decoded_preds, decoded_labels, avg=True, ignore_empty=True)\n\n    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    # result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:59:12.813735Z","iopub.execute_input":"2024-03-29T12:59:12.814456Z","iopub.status.idle":"2024-03-29T12:59:12.821131Z","shell.execute_reply.started":"2024-03-29T12:59:12.814428Z","shell.execute_reply":"2024-03-29T12:59:12.820137Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"## Setting Training Arguments","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"bart-large-news-sum-fine\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:59:18.651561Z","iopub.execute_input":"2024-03-29T12:59:18.652300Z","iopub.status.idle":"2024-03-29T12:59:18.658316Z","shell.execute_reply.started":"2024-03-29T12:59:18.652272Z","shell.execute_reply":"2024-03-29T12:59:18.657304Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model = bart_large_model,\n    args = training_args,\n    train_dataset = bart_large_tokenized_data[\"train\"],\n    eval_dataset = bart_large_tokenized_data[\"val\"],\n    tokenizer = bart_large_tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:59:22.394764Z","iopub.execute_input":"2024-03-29T12:59:22.395531Z","iopub.status.idle":"2024-03-29T12:59:22.417705Z","shell.execute_reply.started":"2024-03-29T12:59:22.395500Z","shell.execute_reply":"2024-03-29T12:59:22.416765Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:59:27.053311Z","iopub.execute_input":"2024-03-29T12:59:27.054149Z","iopub.status.idle":"2024-03-29T14:11:34.881296Z","shell.execute_reply.started":"2024-03-29T12:59:27.054119Z","shell.execute_reply":"2024-03-29T14:11:34.880360Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='885' max='885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [885/885 1:12:05, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.466648</td>\n      <td>{'r': 0.5513922726518424, 'p': 0.49765570977049306, 'f': 0.5203058915324223}</td>\n      <td>{'r': 0.30436257294222074, 'p': 0.26819716891540835, 'f': 0.28357309855627255}</td>\n      <td>{'r': 0.5030421308027588, 'p': 0.4542066066608883, 'f': 0.4747898388590857}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.447289</td>\n      <td>{'r': 0.5479768915889259, 'p': 0.495532934738148, 'f': 0.5179448770220181}</td>\n      <td>{'r': 0.303188275117596, 'p': 0.2674060799628405, 'f': 0.28281248116638374}</td>\n      <td>{'r': 0.49876597127797895, 'p': 0.4511902347444576, 'f': 0.4715208198355528}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.322300</td>\n      <td>1.466044</td>\n      <td>{'r': 0.5582892879550762, 'p': 0.49033888336391523, 'f': 0.5198464124648229}</td>\n      <td>{'r': 0.3088090992622457, 'p': 0.26405719408063544, 'f': 0.2834688467630489}</td>\n      <td>{'r': 0.5089111927117953, 'p': 0.44705309446249314, 'f': 0.4739243377073237}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.322300</td>\n      <td>1.497634</td>\n      <td>{'r': 0.55141837580872, 'p': 0.49024787679390586, 'f': 0.5168736806972768}</td>\n      <td>{'r': 0.3024620376720677, 'p': 0.2622582569880217, 'f': 0.2797803502404694}</td>\n      <td>{'r': 0.500987746720903, 'p': 0.4456745105318896, 'f': 0.46973820969771496}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.322300</td>\n      <td>1.527477</td>\n      <td>{'r': 0.549482603818736, 'p': 0.4924769306470366, 'f': 0.5171717309063367}</td>\n      <td>{'r': 0.30107894552286635, 'p': 0.26399058914475143, 'f': 0.28014563269123727}</td>\n      <td>{'r': 0.49879938453296546, 'p': 0.4473449307521337, 'f': 0.4696280620352501}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=885, training_loss=1.1490949210474046, metrics={'train_runtime': 4327.3487, 'train_samples_per_second': 3.257, 'train_steps_per_second': 0.205, 'total_flos': 1.5251438830485504e+16, 'train_loss': 1.1490949210474046, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Save Model","metadata":{}},{"cell_type":"code","source":"# save the model\nmodel_path = \"bart-large-news-sum-fine\"\ntrainer.save_model(model_path)\nbart_large_tokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:11:41.903372Z","iopub.execute_input":"2024-03-29T14:11:41.903761Z","iopub.status.idle":"2024-03-29T14:11:45.507776Z","shell.execute_reply.started":"2024-03-29T14:11:41.903732Z","shell.execute_reply":"2024-03-29T14:11:45.506647Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"('bart-large-news-sum-fine/tokenizer_config.json',\n 'bart-large-news-sum-fine/special_tokens_map.json',\n 'bart-large-news-sum-fine/vocab.json',\n 'bart-large-news-sum-fine/merges.txt',\n 'bart-large-news-sum-fine/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Inferencing ","metadata":{}},{"cell_type":"markdown","source":"#### Load Trained Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nmodel = BartForConditionalGeneration.from_pretrained(\"/kaggle/working/bart-large-news-sum-fine\").to(device)\ntokenizer = BartTokenizer.from_pretrained(\"/kaggle/working/bart-large-news-sum-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:12:11.482531Z","iopub.execute_input":"2024-03-29T14:12:11.483166Z","iopub.status.idle":"2024-03-29T14:12:13.582787Z","shell.execute_reply.started":"2024-03-29T14:12:11.483135Z","shell.execute_reply":"2024-03-29T14:12:13.581947Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"### Create Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nbart_large_summarizer = pipeline(\"summarization\", model = model,tokenizer = tokenizer, device=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:12:31.393549Z","iopub.execute_input":"2024-03-29T14:12:31.394428Z","iopub.status.idle":"2024-03-29T14:12:31.501464Z","shell.execute_reply.started":"2024-03-29T14:12:31.394395Z","shell.execute_reply":"2024-03-29T14:12:31.500703Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"### Inference on some instances","metadata":{}},{"cell_type":"code","source":"for i in range(3):\n    summary = bart_large_summarizer(test_news['news'].iloc[i])\n    print(\"Reference Summary:- \", test_news['summary'].iloc[i])\n    print(\"\\nGenerated Summary:- \",summary[0]['summary_text'])\n    print(\"==\"*50)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:12:34.845399Z","iopub.execute_input":"2024-03-29T14:12:34.846274Z","iopub.status.idle":"2024-03-29T14:12:38.108649Z","shell.execute_reply.started":"2024-03-29T14:12:34.846242Z","shell.execute_reply":"2024-03-29T14:12:38.107621Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Reference Summary:-  the indian space research organisation isro is set to launch record 103 satellites in a single flight in february first week . as many as 100 of the satellites to be launched are from foreign nations . earlier isro had said it will launch 83 satellites but the launch got delayed due to the addition of more satellites an official said .\n\nGenerated Summary:-  the indian space research organisation isro is all set to launch a record 103 satellites in one go using its workhorse pslvc37 in the first week of february . as many as 100 of the satellites set for launch belong to foreign nations including the united states and germany . we are making a century by launching over 100 satellites at one go said an isro official .\n====================================================================================================\n\nReference Summary:-  women and children will be allowed to use toilet facilities at hotels and restaurants including fivestars in south delhi for free from may 1 . security concerns coupled with the fact that some restaurants and bars dont allow single males made us keep men out of the scheme for now national restaurants association head riaz amlani said .\n\nGenerated Summary:-  starting monday women and children in south delhi restaurants will be able to use public washrooms free of cost by simply walking into the nearest restaurant and conveying their need to the staff . however men have been kept out of the scheme due to privacy issues cited by various hotel associations . security concerns and the fact that some restaurants dont allow single males made us keep men out for now an association official said .\n====================================================================================================\n\nReference Summary:-  an image of a pregnant us president donald trump being hugged by russian president vladimir putin from behind was projected on buildings in new york along with lovethroughhate . the image was a part of an ad campaign by the dating app hater . were just trying to make people laugh . through humour hate can turn into love the apps representatives said .\n\nGenerated Summary:-  a picture of russian president vladimir putin embracing us president donald trump from behind was projected on some buildings in new york and neighbourhoods williamsburg and chelsea with the hashtag lovethroughhate . the image was part of a publicity stunt by a dating app called hater . hater matches potential dates based on the things people mutually hate .\n====================================================================================================\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing on Test Set","metadata":{}},{"cell_type":"code","source":"def generate_summary_bart_large(text):\n    summary = bart_large_summarizer(text)\n    return summary[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:12:42.912404Z","iopub.execute_input":"2024-03-29T14:12:42.913038Z","iopub.status.idle":"2024-03-29T14:12:42.917666Z","shell.execute_reply.started":"2024-03-29T14:12:42.913007Z","shell.execute_reply":"2024-03-29T14:12:42.916616Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"test_news['bart_large_summary'] = test_news['news'].apply(lambda x: generate_summary_bart_large(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:12:57.583065Z","iopub.execute_input":"2024-03-29T14:12:57.583798Z","iopub.status.idle":"2024-03-29T14:20:43.632199Z","shell.execute_reply.started":"2024-03-29T14:12:57.583766Z","shell.execute_reply":"2024-03-29T14:20:43.631365Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stderr","text":"Your max_length is set to 142, but your input_length is only 92. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nYour max_length is set to 142, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\nYour max_length is set to 142, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\nYour max_length is set to 142, but your input_length is only 110. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\nYour max_length is set to 142, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\nYour max_length is set to 142, but your input_length is only 88. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\nYour max_length is set to 142, but your input_length is only 79. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\nYour max_length is set to 142, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\nYour max_length is set to 142, but your input_length is only 125. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\nYour max_length is set to 142, but your input_length is only 114. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\nYour max_length is set to 142, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\nYour max_length is set to 142, but your input_length is only 106. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=53)\nYour max_length is set to 142, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\nYour max_length is set to 142, but your input_length is only 121. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\nYour max_length is set to 142, but your input_length is only 135. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\nYour max_length is set to 142, but your input_length is only 128. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\nYour max_length is set to 142, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\nYour max_length is set to 142, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\nYour max_length is set to 142, but your input_length is only 135. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\nYour max_length is set to 142, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\nYour max_length is set to 142, but your input_length is only 70. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\nYour max_length is set to 142, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\nYour max_length is set to 142, but your input_length is only 111. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\nYour max_length is set to 142, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\nYour max_length is set to 142, but your input_length is only 57. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\nYour max_length is set to 142, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate on Test Data","metadata":{}},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef evaluate_test_summaries(news_data):\n    scorer = rouge_scorer.RougeScorer(rouge_types=['rouge1', 'rouge2', 'rougeL'])\n    rouge_scores = []\n\n    for idx, row in test_news.iterrows():\n        scores = scorer.score(target=row['summary'], prediction=row['bart_large_summary'])\n        rouge_scores.append(scores)\n\n    avg_rouge1_precision = np.mean([score['rouge1'].precision for score in rouge_scores])\n    avg_rouge1_recall = np.mean([score['rouge1'].recall for score in rouge_scores])\n    avg_rouge1_f1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n\n    avg_rouge2_precision = np.mean([score['rouge2'].precision for score in rouge_scores])\n    avg_rouge2_recall = np.mean([score['rouge2'].recall for score in rouge_scores])\n    avg_rouge2_f1 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n\n    avg_rougeL_precision = np.mean([score['rougeL'].precision for score in rouge_scores])\n    avg_rougeL_recall = np.mean([score['rougeL'].recall for score in rouge_scores])\n    avg_rougeL_f1 = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n\n    print(\"Average ROUGE-1 Precision: \", avg_rouge1_precision)\n    print(\"Average ROUGE-1 Recall: \", avg_rouge1_recall)\n    print(\"Average ROUGE-1 F1-Score: \", avg_rouge1_f1)\n    print(\"Average ROUGE-2 Precision: \", avg_rouge2_precision)\n    print(\"Average ROUGE-2 Recall: \", avg_rouge2_recall)\n    print(\"Average ROUGE-2 F1-Score: \", avg_rouge2_f1)\n    print(\"Average ROUGE-L Precision: \", avg_rougeL_precision)\n    print(\"Average ROUGE-L Recall: \", avg_rougeL_recall)\n    print(\"Average ROUGE-L F1-Score: \", avg_rougeL_f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:21:50.356018Z","iopub.execute_input":"2024-03-29T14:21:50.357024Z","iopub.status.idle":"2024-03-29T14:21:50.368081Z","shell.execute_reply.started":"2024-03-29T14:21:50.356992Z","shell.execute_reply":"2024-03-29T14:21:50.367074Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"print(\"For Bart-Large (FineTuned):- \")\nprint(\"\\nEvaluation for the test summary: \\n\")\nevaluate_test_summaries(test_news)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:21:54.399590Z","iopub.execute_input":"2024-03-29T14:21:54.399989Z","iopub.status.idle":"2024-03-29T14:21:55.540602Z","shell.execute_reply.started":"2024-03-29T14:21:54.399962Z","shell.execute_reply":"2024-03-29T14:21:55.539661Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"For Bart-Large (FineTuned):- \n\nEvaluation for the test summary: \n\nAverage ROUGE-1 Precision:  0.48548995236352377\nAverage ROUGE-1 Recall:  0.5499142414029417\nAverage ROUGE-1 F1-Score:  0.5140280644783877\nAverage ROUGE-2 Precision:  0.2712282359526478\nAverage ROUGE-2 Recall:  0.30684569606784096\nAverage ROUGE-2 F1-Score:  0.2869888696243616\nAverage ROUGE-L Precision:  0.3635404133469843\nAverage ROUGE-L Recall:  0.41113379651930215\nAverage ROUGE-L F1-Score:  0.3846138362117907\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Download Saved Model","metadata":{}},{"cell_type":"markdown","source":"### Create Zip File ","metadata":{}},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/bart-base-news-sum-fine\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:56:23.312860Z","iopub.execute_input":"2024-03-29T14:56:23.313233Z","iopub.status.idle":"2024-03-29T14:56:23.409290Z","shell.execute_reply.started":"2024-03-29T14:56:23.313207Z","shell.execute_reply":"2024-03-29T14:56:23.408396Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"import shutil\n# Define the directory containing your model files\nmodel_directory = \"/kaggle/working/bart-large-news-sum-fine\"\n# Define the name for your zip file\nzip_file_name = \"bart-large-news-sum-fine\"\n# Create a zip file containing the model directory\nshutil.make_archive(zip_file_name, 'zip', model_directory)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:26:12.993866Z","iopub.execute_input":"2024-03-29T14:26:12.994528Z","iopub.status.idle":"2024-03-29T14:32:17.813345Z","shell.execute_reply.started":"2024-03-29T14:26:12.994496Z","shell.execute_reply":"2024-03-29T14:32:17.812422Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/bart-large-news-sum-fine.zip'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Get Downloadable Link","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:32:42.195734Z","iopub.execute_input":"2024-03-29T14:32:42.196109Z","iopub.status.idle":"2024-03-29T14:32:43.333797Z","shell.execute_reply.started":"2024-03-29T14:32:42.196080Z","shell.execute_reply":"2024-03-29T14:32:43.332735Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"bart-base-news-sum-fine       t5-base-news-sum-fine.zip\nbart-base-news-sum-fine.zip   t5-small-news-sum-fine.zip\nbart-large-news-sum-fine      test_news.csv\nbart-large-news-sum-fine.zip  train_news.csv\nfiltered_news_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'bart-large-news-sum-fine.zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:32:54.326970Z","iopub.execute_input":"2024-03-29T14:32:54.327390Z","iopub.status.idle":"2024-03-29T14:32:54.335031Z","shell.execute_reply.started":"2024-03-29T14:32:54.327351Z","shell.execute_reply":"2024-03-29T14:32:54.334042Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/bart-large-news-sum-fine.zip","text/html":"<a href='bart-large-news-sum-fine.zip' target='_blank'>bart-large-news-sum-fine.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving all Test Summaries","metadata":{}},{"cell_type":"code","source":"test_news.to_csv('/kaggle/working/all_test_news_summaries.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T14:57:54.332137Z","iopub.execute_input":"2024-03-29T14:57:54.332565Z","iopub.status.idle":"2024-03-29T14:57:54.403716Z","shell.execute_reply.started":"2024-03-29T14:57:54.332532Z","shell.execute_reply":"2024-03-29T14:57:54.402756Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}